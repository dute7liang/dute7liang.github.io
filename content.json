[{"title":"ZooKeeper","date":"2019-12-30T15:12:12.000Z","path":"2019/12/30/zookeeper/","text":"zookeeper前言在现在分布式、微服务大行其道的今天，肯定都会接触ZooKeeper这个框架。本人也只是在Dubbo的项目中有使用过(当然Kafka的集群部署也是基于ZooKeeper,这个就不算使用了)。但是它可以做的事远不止在Dubbo中的使用。所以先了解了ZooKeeper的基本模型、概念以及使用，以便加深学习 zookeeper是什么ZooKeeper 是一个开源的分布式协调服务,设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。 ZooKeeper 是一个典型的分布式数据一致性解决方案。其主要应用场景： master节点选举，主节点挂了以后，从节点就会接收工作，并且节点是唯一的。保证高可用（比如Kafka集群） 统一配置文件管理，即只需要部署一台服务器，则可以把相同的配置文件同步更新到其他服务器。 发布与订阅。类似于消息队列MQ，dubbo发布者把数据发布到znode上，订阅者会拉出数据 分布式锁 集群管理，集群中保证数据的强一致性（Dubbo的注册中心） 本人主要接触ZooKeeper还是在公司使用Dubbo的时候接触的，所以ZooKeeper主要是用于：服务的容错、负载均衡、查找服务和管理服务，还可以选择其作为配置中心的集中式管理。 ZooKeeper的数据模型Session机制在了解ZooKeeper的数据模型之前，有必要了解ZooKeeper的Session机制 Session是指客户端和服务端之间会话。在ZooKeeper中是指一个客户端与ZooKeeper之间的一次长连接。客户端在启动时会与服务端建立一个Tcp连接。后续客户端可已通过这个连接发送消息给服务端，也可以监听服务端发送来的消息。客户端和服务端有一个心跳机制来维持和判断这个连接的有效性，可以通过Session中的sessionTimeout值来设置一个客户端的超时时间。同时当由于服务器原因或者客户端主动要求端口连接的时候，只要在超时时间内重新连接任一一台ZooKeeper机器，那么之前创建的 Session仍然有效。 和我们平常接触到HttpSession一样，每次创建一次会话，服务端都会为该客户端分配一个SessionId，该SessionId也是全局唯一的。 数据模型ZooKeeper的数据模型和我们经常使用的Unix/Linux的文件系统是类似的。 上图中我们可以比较明显看到和文件系统很像，实际它提供的操作API都有点类似。正确情况下，我们会在会根目录下创建一个自己项目的Znode。比如dubbo、kafka以便隔离数据。和我们创建文件夹的思路一样 znode 在ZooKeeper中每一个节点都称之为znode，它本身可以有子节点，也可以有数据。 每一个节点分为临时节点和永久节点，临时节点在客户端断开后消失。也就是Session超时 每一个节点都有各自的版本号。可以通过命令行来显示节点信息 没当节点的数据发生改变，那么该节点的版本号都会累加（乐观锁） 删除、修改节点时，如果版本号不匹配会报错（乐观锁） 由于ZooKeeper的数据都存在内存中，每个节点的数据不建议存储过大的数据。几K即可 节点也可以设置acl权限。可以通过权限来限制用户的操作（unix的文件权限） 这里需要注意znode分为临时节点和永久节点，临时节点在session关闭时会自动删除 watch机制ZooKeeper在针对每个节点的操作，都会有监督者（watcher），当监控对象znode发生了变化，则触发watcher事件，可以理解为监听器。zk中的watcher是一次性的，触发后立即销毁 父节点、子节点 增删改都能够触发watcher事件。 具体的watcher事件 创建节点触发， NodeCreated 修改节点触发，NodeDataChanged 删除节点触发，NodeDeleted 增加子节点触发，NodeChildrenChanged 删除子节点触发，NodeChildrenChanged 修改子节点不触发监听 这里我建议自己在命令行或者用代码api来自己体验下 ZooKeeper命令行了解基本的命令行，其实ZooKeeper的命令行并不多，这里只做简单介绍 执行./zkCli.sh即可打开命令行 查询命令ls path [watch] 查询目录 watch 设置子节点的watch事件 stat path [watch] 查询详细信息 watch 设置当前节点的watch事件（下面的watch都是类似的机制不在说明） 节点信息如下： cZxid 创建的id ctime 创建的时间 mZxid 修改的id mtime 修改的时间 pZxid 父节点的id cversion 子节点的version dataVersion 数据的version aclVersion 权限的version ephemeraOwner 0x0为永久节点，其他为临时节点（待定） datalength 数据长度 numChildren 子节点的大小 zxid:ZooKeeper状态的每一次改变, 都对应着一个递增的Transaction id, 该id称为zxid. 由于zxid的递增性质, 如果zxid1小于zxid2, 那么zxid1肯定先于zxid2发生创建任意节点, 或者更新任意节点的数据, 或者删除任意节点, 都会导致Zookeeper状态发生改变, 从而导致zxid的值增加. ls2 path [watch] 查询目录,同时展示节点的信息 get path [watch] 可以将目录的数据取出来 创建命令create [-s] [-e] path data acl -e 临时节点-s 顺序节点 在创建文件夹会在后面自动添加1开始的顺序 create /test/name hello-world 修改命令set path data [version] version 主要用于更新时的乐观锁 删除命令delete path [version] version 主要用于删除时的乐观锁 ZooKeeper的集群前面已经了解的ZooKeeper的概念，已经他能够为我们做什么。现在来了解一下ZooKeeper是怎么保证数据的统一性。以及自身集群的高可用。 ZooKeeper 中的角色ZooKeeper在实际生产环境中是推荐使用集群方式。 在ZooKeeper的集群中引入了Leader、Follower、Observer三种角色。如下图所示 ZooKeeper集群中的所有机器会通过Leader选举过程来选定一台成为Leader的机器。该Leader既可以为客户端提供读服务和写服务，但是Follower和Observer都只能提供读服务。Follower和Observer的唯一区别就是不参与Leader的选举过程，Observer仅仅是用提升服务的读取速度而存在的。因为Follower的无限增多也会影响选举的性能。 ZooKeeper的核心是原子广播，这个机制保证各个Server之间的同步。实现这个机制的协议叫Zab协议。Zab协议有两种模式：恢复模式（选主）和广播模式（同步） 当Leader服务器出现崩溃，重启，网络中断等异常情况时，Zab协议会进入恢复模式并选举出新的Leader服务 大致步骤如下： Leader election（选举阶段）：节点在一开始都处于选举阶段，只要有一个节点得到超半数节点的票数，它就可以当选准 leader。 Discovery（发现阶段）：在这个阶段，followers 跟准 leader 进行通信，同步 followers 最近接收的事务提议。 Synchronization（同步阶段）:同步阶段主要是利用 leader 前一阶段获得的最新提议历史，同步集群中所有的副本。同步完成之后 准 leader 才会成为真正的 leader。 Broadcast（广播阶段） 到了这个阶段，Zookeeper 集群才能正式对外提供事务服务，并且 leader 可以进行消息广播。同时如果有新的节点加入，还需要对新节点进行同步。 这里通过第一条的规则，所以ZooKeeper部署推荐为单数服务，假如3台机器。最大允许宕机一台。而四台机器也是最大允许宕机一台。所以并不推荐部署双数机器部署 ZooKeeper的读写机制 Zookeeper是一个由多个server组成的集群 一个leader，多个follower 每个server保存一份数据副本 全局数据一致 分布式读写 更新请求转发，由leader实施 Zookeeper的保证 更新请求顺序进行，来自同一个client的更新请求按其发送顺序依次执行 数据更新原子性，一次数据更新要么成功，要么失败 全局唯一数据视图，client无论连接到哪个server，数据视图都是一致的 实时性，在一定事件范围内，client能读到最新数据 Zookeeper的选举方式首先选举必须要半数通过才行 简单模拟一下： A提案说，我要选自己，B你同意吗？C你同意吗？B说，我同意选A；C说，我同意选A。(注意，这里超过半数了，其实在现实世界选举已经成功了。但是计算机世界是很严格，另外要理解算法，要继续模拟下去。) 接着B提案说，我要选自己，A你同意吗；A说，我已经超半数同意当选，你的提案无效；C说，A已经超半数同意当选，B提案无效。 接着C提案说，我要选自己，A你同意吗；A说，我已经超半数同意当选，你的提案无效；B说，A已经超半数同意当选，C的提案无效。 选举已经产生了Leader，后面的都是follower，只能服从Leader的命令。而且这里还有个小细节，就是其实谁先启动谁当头。 Zab协议和Paxos算法Paxos算法应该可以说是ZooKeeper的灵魂了。但是ZooKeeper并没有完全采用Paxos算法 ，而是使用ZAB协议作为其保证数据一致性的核心算法。另外，在ZooKeeper的官方文档中也指出，ZAB协议并不像Paxos算法那样，是一种通用的分布式一致性算法，它是一种特别为Zookeeper设计的崩溃可恢复的原子消息广播算法。 这里Paxos算法暂时没什么了解，可以参考一些文章和一些书籍了解 从Paxos到ZooKeeper 图解分布式一致性协议Paxos 实例详解ZooKeeper ZAB协议、分布式锁与领导选举 总结 ZooKeeper本身就是一个分布式程序。超过半数以上存活，ZooKeeper就能正常服务 ZooKeeper的数据保存在内中，保证低延迟和高吞吐量，也不建议在znode中保存过大的数据 ZooKeeper推荐使用在读多写少的场景写，上面我们可以到了ZooKeeper只有leader才能执行写操作，这样做确实天然的保证的其顺序性，但是也影响了性能 znode有临时节点和永久节点的区分，临时节点在Session关闭时删除。（Session的关闭时通过Session超时来决定的，如果断开后再超时时间连上来Session是会继续维持） ZooKeeper对于客户端主要提供两个操作：数据的增删改查和数据的监听服务 参考 https://www.cnblogs.com/raphael5200/p/5285583.html","tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"分布式锁","date":"2019-12-30T15:12:12.000Z","path":"2019/12/30/分布式锁/","text":"分布式锁前言分布式项目中必然而然的肯定会接触到分布式锁，相比诸如限流、熔断、分布式锁等其他技术。分布式锁在分布式项目是肯定会遇到的。因为其他技术可能在你的项目使用人数不多，业务简单而不需要。但是分布式锁在业务上基本是必须处理的。 目前分布式锁主流的实现方案有:redis分布式锁、ZooKeeper分布式锁两种。当然还有其他，比如基础关系型数据库来做分布式锁也有。这里只讲这两个。 redis分布式锁基本原理-RedLockredis分布式锁，在redis官方叫RedLock。其实现也主要分为两个阶段。 加锁-RedLockredis中加锁主要通过set命令来解决其中还用到了nx和px参数(在redis2.6.12版本后set命令增加了很多新的参数，所以理论上setnx、setex、psetex会被set命令取代，后续也不推荐使用以上命令，可能后续版本会被不推荐或者移除，具体可查看官网)来控制。 SET key my_random_value NX PX 30000 比如通过以上命令就可以获取锁，由于NX的特性只有在key不存在时才能设置成功保证了锁的独占性，而PX则保证了在锁的安全性，避免获取锁的客户端在崩溃后，锁能够自然释放掉。其中my_random_value可以设置为一个随机值，必须保证该值得全局唯一性 解锁-RedLock解锁的过程就可以直接使用DEL命令来解决，但是为了保证加锁和解锁是同一个客户端，所以我们要校验一下my_random_value是否正确。这里可以为了保证其原子性可以使用Lua脚本来完成 12345if redis.call(\"get\",KEYS[1]) == ARGV[1] then return redis.call(\"del\",KEYS[1])else return 0end 以上就是最基本的redis锁的原理 缺点这种锁肯定也有缺点。在redis主从哨兵的环境中。比如我们在主服务器获取了锁。此时主服务宕机。由于redis主从复制的异步特性，该key值没有同步到从服务器。并且完成了选举，此时第二个客户端就可能直接在新的主服务器获取到锁。所以就可能存在两个客户端同时获取到锁。 所以我们在核心业务的逻辑处理中要自己去保证被加锁的代码块的幂等性，不会因为分布式锁的问题而导致出现核心业务受损。 不知道有什么完美的解决方案，对redis内部的架构不大了解。待定！ RedissonRedisson是redis的一个java客户端。也是redis官网推荐的客户端（Spring-data-redis默认使用的Jedis），其中Redisson也对redis的分布式锁进行封装处理。比如对其支持可重复锁，公平锁等扩张，以便我们更好的使用Redis分布式锁。来简单看下Redisson的内部源码实现 这里首先要特别注意下由于Redisson的版本更迭比较快，我发现锁的内部实现代码。每个版本都有一些差异。基本原理都是一样的我用的SpringBoot所以版本也都一样。 Redisson Version : 3.11.3Redisson SpringBoot start Version ：3.11.3 Redisson分布式锁的基本使用Redisson的分布式锁使用和Java中的ReentrantLock的使用是一样的。 123456789101112@Autowiredprivate RedissonClient redissonClient;public void method() throws InterruptedException &#123; RLock lock = redissonClient.getLock(\"myKey\"); try &#123; lock.lock(); // 直接尝试获取锁 lock.tryLock(1, TimeUnit.MINUTES); // 也可以尝试获取锁 1分钟 &#125;finally &#123; lock.unlock(); &#125;&#125; 以上代码就是简单的lock使用。接下来来看下其源码实现 获取lock首先在了解过ReentrantLock的实现上，在看其实现就会简单很多。 先看下RLock lock = redissonClient.getLock(&quot;myKey&quot;);这句主要做了什么。 12345678910111213141516@Overridepublic RLock getLock(String name) &#123; return new RedissonLock(connectionManager.getCommandExecutor(), name); // 构造函数在下面&#125;public RedissonLock(CommandAsyncExecutor commandExecutor, String name) &#123; super(commandExecutor, name); // 命令执行器 this.commandExecutor = commandExecutor; this.id = commandExecutor.getConnectionManager().getId(); // 内部锁过期时间 30000毫秒 this.internalLockLeaseTime = commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(); this.entryName = id + \":\" + name; // redis的发布订阅 this.pubSub = commandExecutor.getConnectionManager().getSubscribeService().getLockPubSub();&#125; Redisson加锁的实现构造函数没有特别的，主要是获取Redis的连接的基本类。和一些默认的参数 lock获取完了，接下来看第二部加锁。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public void lock() &#123; try &#123; lock(-1, null, false); &#125; catch (InterruptedException e) &#123; throw new IllegalStateException(); &#125;&#125;private void lock(long leaseTime, TimeUnit unit, boolean interruptibly) throws InterruptedException &#123; long threadId = Thread.currentThread().getId(); // 获取当前线程id Long ttl = tryAcquire(leaseTime, unit, threadId); // 尝试获取锁 // 获取锁成功 if (ttl == null) &#123; return; &#125; // 如果获取锁失败，则订阅到对应这个锁的channel TODO 这一步还没有仔细看，待定 RFuture&lt;RedissonLockEntry&gt; future = subscribe(threadId); commandExecutor.syncSubscription(future); try &#123; while (true) &#123; ttl = tryAcquire(leaseTime, unit, threadId); // 再次尝试获取锁 // lock acquired if (ttl == null) &#123; break; &#125; // 锁获取失败，等待ttl超时后再尝试获取 if (ttl &gt;= 0) &#123; try &#123; getEntry(threadId).getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS); &#125; catch (InterruptedException e) &#123; if (interruptibly) &#123; throw e; &#125; getEntry(threadId).getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS); &#125; &#125; else &#123; if (interruptibly) &#123; getEntry(threadId).getLatch().acquire(); &#125; else &#123; getEntry(threadId).getLatch().acquireUninterruptibly(); &#125; &#125; &#125; &#125; finally &#123; // 取消订阅 unsubscribe(future, threadId); &#125;// get(lockAsync(leaseTime, unit));&#125; 接下跟下去详细看到尝试获取锁的方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344private &lt;T&gt; RFuture&lt;Long&gt; tryAcquireAsync(long leaseTime, TimeUnit unit, long threadId) &#123; if (leaseTime != -1) &#123; // 带有过期时间的获取锁 return tryLockInnerAsync(leaseTime, unit, threadId, RedisCommands.EVAL_LONG); &#125; // 没有带过期时间，则默认按30000毫秒来获取锁 RFuture&lt;Long&gt; ttlRemainingFuture = tryLockInnerAsync(commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(), TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG); // 如果没有获取到锁，则开启一个定时任务不断的去刷新该锁的过期时间 这里是一个看门狗的角色 ttlRemainingFuture.onComplete((ttlRemaining, e) -&gt; &#123; if (e != null) &#123; return; &#125; // lock acquired if (ttlRemaining == null) &#123; scheduleExpirationRenewal(threadId); &#125; &#125;); return ttlRemainingFuture;&#125;// 接着看tryLockInnerAsync方法// 他使用了lua脚本来设置的，而且使用的Hash结构&lt;T&gt; RFuture&lt;T&gt; tryLockInnerAsync(long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand&lt;T&gt; command) &#123; internalLockLeaseTime = unit.toMillis(leaseTime); return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command, // 锁不存在 hset获取锁，同时设置过期时间 \"if (redis.call('exists', KEYS[1]) == 0) then \" + \"redis.call('hset', KEYS[1], ARGV[2], 1); \" + \"redis.call('pexpire', KEYS[1], ARGV[1]); \" + \"return nil; \" + \"end; \" + // 锁已经存在 // 判断锁是否为当前线程，如果是对其值+1,同时再次设置时间(主要解决可重入锁的问题) \"if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then \" + \"redis.call('hincrby', KEYS[1], ARGV[2], 1); \" + \"redis.call('pexpire', KEYS[1], ARGV[1]); \" + \"return nil; \" + \"end; \" + // 都不是则直接返回锁的ttl \"return redis.call('pttl', KEYS[1]);\", // 下面是三个参数key[1] ARGV[1] ARGV[2] 分别是出传入key，时间，当前线程 // 这里可以去简单了解下lua的调用语法即可 Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId));&#125; 在了解key[1] ARGV[1] ARGV[2]是什么后很简单了。 实际上他为了一个map结构的数据。 key - 锁的名称filed - 随机字符串+线程ID 值为1value - 线程ID 会随着的递增来实现可重入锁 加锁基本就已经完成！ 接着来看下解锁 Redisson解锁的实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Overridepublic RFuture&lt;Void&gt; unlockAsync(long threadId) &#123; RPromise&lt;Void&gt; result = new RedissonPromise&lt;Void&gt;(); RFuture&lt;Boolean&gt; future = unlockInnerAsync(threadId); // 解锁的具体方法 future.onComplete((opStatus, e) -&gt; &#123; if (e != null) &#123; // 锁不存在异常 关闭前面开启的定时任务，抛出异常 cancelExpirationRenewal(threadId); result.tryFailure(e); return; &#125; // 解锁和持锁人不是同一个任务 抛出异常 if (opStatus == null) &#123; IllegalMonitorStateException cause = new IllegalMonitorStateException(\"attempt to unlock lock, not locked by current thread by node id: \" + id + \" thread-id: \" + threadId); result.tryFailure(cause); return; &#125; // 解锁成功 关闭前面开启的定时任务 cancelExpirationRenewal(threadId); result.trySuccess(null); &#125;); return result;&#125;// 接着直接看解锁的代码protected RFuture&lt;Boolean&gt; unlockInnerAsync(long threadId) &#123; // lua脚本 return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN, // 1. 判断锁是否等于当前线程，不等于则返回 \"if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then \" + \"return nil;\" + \"end; \" + // 2. 对锁进行递减 \"local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); \" + // &gt;0 则刷新一下过期时间 \"if (counter &gt; 0) then \" + \"redis.call('pexpire', KEYS[1], ARGV[2]); \" + \"return 0; \" + \"else \" + // 不是则删除key，并同时发布锁释放的消息 \"redis.call('del', KEYS[1]); \" + \"redis.call('publish', KEYS[2], ARGV[1]); \" + \"return 1; \"+ \"end; \" + \"return nil;\", Arrays.&lt;Object&gt;asList(getName(), getChannelName()), LockPubSub.UNLOCK_MESSAGE, internalLockLeaseTime, getLockName(threadId));&#125; Redisson的加锁和解锁基本完成。只需要简单的记住它所维护的map数据结构即可很好的记住它的原理 Redisson中的看门狗Redisson有一个看门狗的角色特别说明下，就是前面说的那个定时任务 首先通过前面的原理已经知道Redis在加锁的时候是会设置一下key的时间的。假如在持有锁的客户端在设置的时间内依然正在执行中，那么就很有可能锁被其他客户端拿到造成两个客户端同时获取到锁。为了解决这个问题才引入了看门狗这个角色。它主要监控获取锁的线程如果该线程一直在运行中，它可以为这个锁的时间来续约。默认是每次续约30000毫秒。 这个角色具体有兴趣可以自己看下源码。 ZooKeeper分布式锁ZooKeeper的分布式锁首先我们要知道ZooKeeper的基本原理和内存模型。具体可以看我的另外一篇文章，这里不多做介绍了！ 基本原理-Zookeeper加锁-ZooKeeper加锁主要是通过zookeeper来创建一个临时顺序节点。然后检查自己的节点是否为顺序中最小的那一个，如果不是则监听自己上一个顺序的节点等待被唤醒 实际就是类似维护了一个FIFO的队列，然后依次监听自己的上一个节点。就像链式结构一样 这里的临时节点可以保证，自己掉线后，由zookeeper来删除节点，最后通知下一个节点。保证链式不断。 解锁-ZooKeeper解锁就比较简单了。删除自己的节点即可。通过zookeeper的监听机制来通知其他节点 Curator既然Redis推荐Redisson，那么ZooKeeper肯定推荐的实现代码！这里推荐curator客户端。同时是基于ZooKeeper做一些开发。可推荐使用该客户端。因为原生客户端不大好用，比如由于ZooKeeper的watch绑定机制每次触发一次就会失效需要重新绑定。这里该客户端已经帮我们实现了动态绑定。避免我们写代码时忘记。详细使用可以自己查看官网了！ Curator的基本使用这里用的版本是2.8.0，其他版本的源码可能有些许出入。 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt;&lt;/dependency&gt; 这里简单看下使用的代码。非常简单。上面那部分代码可以集成在Spring中。统一使用CuratorFramework即可 12345678910111213141516ExponentialBackoffRetry retry = new ExponentialBackoffRetry(1000, 3);CuratorFramework framework = CuratorFrameworkFactory.builder() .connectString(\"192.168.72.253:2181,192.168.72.253:2182,192.168.72.253:2183\") .sessionTimeoutMs(50000) .connectionTimeoutMs(50000) .retryPolicy(retry) .namespace(\"duteliang\") .build();framework.start();InterProcessMutex interProcessMutex = new InterProcessMutex(framework,\"/zl/lock/name\");try &#123; interProcessMutex.acquire(); // 加锁&#125; finally &#123; interProcessMutex.release(); // 解锁&#125; Curator加锁的实现简单看下internalLock的内部实现 1234567891011121314151617181920private boolean internalLock(long time, TimeUnit unit) throws Exception &#123; // 获取当前线程 Thread currentThread = Thread.currentThread(); // 查询缓存是否已经获取到锁了 LockData lockData = threadData.get(currentThread); if ( lockData != null ) &#123; // 已经获取到锁，可重入锁 lockData.lockCount.incrementAndGet(); // lockCount +1 return true; &#125; // 获取锁 String lockPath = internals.attemptLock(time, unit, getLockNodeBytes()); if ( lockPath != null )&#123; // 获取锁成功，添加缓存 LockData newLockData = new LockData(currentThread, lockPath); threadData.put(currentThread, newLockData); return true; &#125; // 获取锁失败 返回false return false;&#125; 其中重点就是internals.attemptLock获取锁这个方法！继续看源码 1234567891011121314151617181920212223242526272829303132333435363738String attemptLock(long time, TimeUnit unit, byte[] lockNodeBytes) throws Exception &#123; final long startMillis = System.currentTimeMillis(); final Long millisToWait = (unit != null) ? unit.toMillis(time) : null; final byte[] localLockNodeBytes = (revocable.get() != null) ? new byte[0] : lockNodeBytes; int retryCount = 0; String ourPath = null; boolean hasTheLock = false; boolean isDone = false; while ( !isDone )&#123; isDone = true; try&#123; // 创建节点, 临时、顺序节点 ourPath = driver.createsTheLock(client, path, localLockNodeBytes); // 判断是否获取锁，同时阻塞自己。关键部分 hasTheLock = internalLockLoop(startMillis, millisToWait, ourPath); &#125;catch ( KeeperException.NoNodeException e )&#123; if ( client.getZookeeperClient().getRetryPolicy().allowRetry(retryCount++, System.currentTimeMillis() - startMillis, RetryLoop.getDefaultRetrySleeper()) )&#123; isDone = false; &#125;else&#123; throw e; &#125; &#125; &#125; if ( hasTheLock )&#123; return ourPath; &#125; return null;&#125;// 创建节点, 临时、顺序节点public String createsTheLock(CuratorFramework client, String path, byte[] lockNodeBytes) throws Exception &#123; String ourPath; if (lockNodeBytes != null) &#123; ourPath = client.create().creatingParentsIfNeeded().withProtection().withMode(CreateMode.EPHEMERAL_SEQUENTIAL).forPath(path, lockNodeBytes); &#125; else &#123; ourPath = client.create().creatingParentsIfNeeded().withProtection().withMode(CreateMode.EPHEMERAL_SEQUENTIAL).forPath(path); &#125; return ourPath;&#125; 这一步主要就是两步 创建临时顺序节点 循环对顺序节点和自己进行检查，来判断自己是否可以获取锁 接下来看第二部的代码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061private boolean internalLockLoop(long startMillis, Long millisToWait, String ourPath) throws Exception &#123; boolean haveTheLock = false; boolean doDelete = false; try &#123; // 这一步是实现可撤销锁的动作，具体还没有研究 if (revocable.get() != null) &#123; client.getData().usingWatcher(revocableWatcher).forPath(ourPath); &#125; // 循环获取锁 while ((client.getState() == CuratorFrameworkState.STARTED) &amp;&amp; !haveTheLock) &#123; List&lt;String&gt; children = getSortedChildren(); // 获取所有顺序节点，注意已经排序好了。从小到大 String sequenceNodeName = ourPath.substring(basePath.length() + 1); // 获取顺序节点的名称 // 这一步就不贴源码了，可以自己看下比较简单 // 主要判断当前节点是否为所有节点的第一个，如果是则获取到锁sTheLock=true, // 如果不是则获取到上一个顺序节点的名称 PredicateResults predicateResults = driver.getsTheLock(client, children, sequenceNodeName, maxLeases); if (predicateResults.getsTheLock()) &#123; // 获取到锁，返回 haveTheLock = true; &#125; else &#123; String previousSequencePath = basePath + \"/\" + predicateResults.getPathToWatch(); // 上一个顺序节点的完成名称 synchronized (this) &#123; try &#123; // 监听上一个节点、监听内代码在下面有贴。简单的notifyAll代码 client.getData().usingWatcher(watcher).forPath(previousSequencePath); if (millisToWait != null) &#123; // wait 开始阻塞线程等待 millisToWait -= (System.currentTimeMillis() - startMillis); startMillis = System.currentTimeMillis(); if (millisToWait &lt;= 0) &#123; doDelete = true; break; &#125; wait(millisToWait); &#125; else &#123; wait(); &#125; &#125; catch (KeeperException.NoNodeException e) &#123; // it has been deleted (i.e. lock released). Try to acquire again &#125; &#125; &#125; &#125; &#125; catch (Exception e) &#123; doDelete = true; throw e; &#125; finally &#123; if (doDelete) &#123; // 如果出现程序异常，则删除自己的节点。 deleteOurPath(ourPath); &#125; &#125; return haveTheLock;&#125;// 这里补充一下监听的代码。主要做了什么。// 主要通过 wait 和 notifyAll 的组合来处理private synchronized void notifyFromWatcher()&#123; notifyAll();&#125; 从代码可以看出，其主要逻辑 获取所有顺序节点 判断自己是否为顺序中最小的那个节点，是就获取锁 不是则获取自己上一个节点，然后watch它。等待唤醒 这里为了便于理解可以参考一下下面的逻辑图 Curator解锁的实现解锁就是比较简单了。就是删除节点。不多介绍。 12345678910111213141516171819202122public void release() throws Exception &#123; Thread currentThread = Thread.currentThread(); InterProcessMutex.LockData lockData = threadData.get(currentThread); if (lockData == null) &#123; // 当前没有获取到锁。解锁失败 throw new IllegalMonitorStateException(\"You do not own the lock: \" + basePath); &#125; int newLockCount = lockData.lockCount.decrementAndGet(); if (newLockCount &gt; 0) &#123; // 解锁成功 return; &#125; if (newLockCount &lt; 0) &#123; // 小于0，程序不正常。抛出异常 throw new IllegalMonitorStateException(\"Lock count has gone negative for lock: \" + basePath); &#125; try &#123; // 删除节点，触发监听器 internals.releaseLock(lockData.lockPath); &#125; finally &#123; // 删除缓存 threadData.remove(currentThread); &#125;&#125; 总结这里基本讲完了Redis和ZooKeeper分布式锁的原理和实现。当然了解原理后可以自己去滚轮子，但是要注意很多细节部分。推荐还是直接使用上面的框架。 那么Redis和ZooKeeper分布式锁，哪个好一点了。 我认为首先两者在性能上面都是完全能够在生产环境使用的，两者之间的主要区别在于： Redis分布式锁上面已经讲过在主从集群环境中，有一个缺点。就是有可能两个客户端同时获取到锁，ZooKeeper就不存在这种。这主要是两者设计理念所造成的。就是我们常说的CAP原则，ZooKeeper保证的是CP（容错性和一致性），而redis保证的是AP（容错性和可用性）。具体可以去了解一下CAP的设计原则。 ZooKeeper在锁等待时会阻塞线程，不需要通过循环来解决。这也是由于ZooKeeper天然提供watch机制所带来的好处 ZooKeeper由于CP所带来的强一致性，性能没有redis好，同时由于ZooKeeper的实现中频繁的删除添加节点也有影响。但是ZooKeeper并不慢，只是与Redis比较而言 所以如果能使用ZooKeeper我还是推荐使用ZooKeeper，但是ZooKeeper在项目中很多时候是作为注册中心来使用（比如dubbo），如果你的项目没有使用ZooKeeper，那么也可以使用Redis来做分布式锁，毕竟大部分项目都会使用Redis来做缓存。 参考文档redis官网set命令说明Distributed locks with Redis分布式锁之Redis实现curator-lock-document","tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"并发基础","date":"2019-04-11T01:58:51.000Z","path":"2019/04/11/javabase/并发基础/","text":"并发基础并发BUG的源头并发的原因现在主流是三种，原子性、可见性、有序性。本质乃是计算机CPU、内存之间的问题。问题本身很复杂，才疏学浅只简单的讲下理解的。目的就是为了有个基本的概率，可以更好的理解并发。 可见性一个线程对共享变量的修改，其他线程是否能够立即看到，就称为可见性。至于为什么会有这个问题，其实主要是因为缓存的问题导致的。在计算机中CPU并不是直接操作内存里面的数据，每个CPU本身也会缓存，CPU只会操作自己缓存的数据，然后CPU缓存和内存进行交互。多线程的情况就会出现缓存和主内存的数据不一致的问题！ CPU缓存和内存的关系图其实在Java的内存模型中，也会出现这种情况，在下图中可以明显看到。JAVA的引用对象，每个线程在修改对象数据时，并不是直接修改内存的数据，而是每个线程都保存了一份实际内存的数据备份。这样也会可见性的问题 原子性原子性的日常理解是：某个单位已经到了最小不可拆分的单位。就说明这个单位具有原子性。在编程中其实也比较好理解，比如 count += 1 就不具备原子性。因为我们都知道他是分为几步完成的 123将count的数据从内存中取出 --&gt; 1count+1 --&gt; 2将count放回内存中 --&gt; 3 这三部在执行过程中。都会出现中断或者多线程的原因其他线程中途也对count进行了操作。这一步操作并不是最小单位。 有序性有序性，就是程序按代码编写的逻辑执行。但是实际情况下程序并不是按代码编写的逻辑执行的，为什么会这样？主要原因是编译优化，比如程序中： int a=1; int b = 2; 正常应该先做a，在做b。但是实际情况并不是确定，有可能b先做，但是在编译优化并不会影响程序在单线程中执行，多线程就不确定了。 在单例模式中的双重检查有一个很经典的例子。 Java内存模型理解以上三种特性后，想要避免多线程的BUG，比如可见性是缓存导致的，我们就禁用缓存。有序性是编译优化导致的，我们就禁用编译优化。这样做确实可以减少很多并发的BUG，但是会导致性能大减。 合理方案应该是按需优化。 现代计算机体系大部是采用的对称多处理器的体系架构。每个处理器均有独立的寄存器组和缓存，多个处理器可同时执行同一进程中的不同线程，这里称为处理器的乱序执行。在Java中，不同的线程可能访问同一个共享或共享变量。如果任由编译器或处理器对这些访问进行优化的话，很有可能出现无法想象的问题，这里称为编译器的重排序。除了处理器的乱序执行、编译器的重排序，还有内存系统的重排序。因此Java语言规范引入了Java内存模型，通过定义多项规则对编译器和处理器进行限制，主要是针对可见性和有序性。 Happens-BeforeHappens-Before 原则主要是Java推出的一些规范。 程序次序规则：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确地说，应该是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。 管程锁定规则：一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是同一个锁，而”后面”是指时间上的先后顺序。 volatile变量规则：对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的”后面”同样是指时间上的先后顺序。 线程启动规则：Thread对象的start()方法先行发生于此线程的每一个动作。 线程终止规则：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread.join（）方法结束、Thread.isAlive（）的返回值等手段检测到线程已经终止执行。 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted()方法检测到是否有中断发生。 对象终结规则：一个对象的初始化完成(构造函数执行结束)先行发生于它的finalize()方法的开始。 volatilevolatile 关键可以对象的可见性以及指令重排序，以为volatile修饰的变量在操作时会通过内存屏障来禁止指令重排序。而且其修饰的关键字在使用变量和更新变量时都会更新内存中的变量缓存和提交线程中的变量缓存。所以解决了可见性的问题，但是无法解决原子性的问题 主要使用用于标记状态、doubleCheck finalfinal关键字申明的对象是无法再修改的，也就天然的保证了其可见性的问题，只有查看而没有修改。（注意final修饰引用对象时，对象内部的引用对象也是可以修改的）。 锁锁主要是解决其原子性的问题。后续会详细讲解","tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/%E5%B9%B6%E5%8F%91/"}]}]