[{"title":"ZooKeeper","date":"2019-12-30T15:12:12.000Z","path":"2019/12/30/microservices/zookeeper/","text":"zookeeper前言在现在分布式、微服务大行其道的今天，肯定都会接触ZooKeeper这个框架。本人也只是在Dubbo的项目中有使用过(当然Kafka的集群部署也是基于ZooKeeper,这个就不算使用了)。但是它可以做的事远不止在Dubbo中的使用。所以先了解了ZooKeeper的基本模型、概念以及使用，以便加深学习 zookeeper是什么ZooKeeper 是一个开源的分布式协调服务,设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。 ZooKeeper 是一个典型的分布式数据一致性解决方案。其主要应用场景： master节点选举，主节点挂了以后，从节点就会接收工作，并且节点是唯一的。保证高可用（比如Kafka集群） 统一配置文件管理，即只需要部署一台服务器，则可以把相同的配置文件同步更新到其他服务器。 发布与订阅。类似于消息队列MQ，dubbo发布者把数据发布到znode上，订阅者会拉出数据 分布式锁 集群管理，集群中保证数据的强一致性（Dubbo的注册中心） 本人主要接触ZooKeeper还是在公司使用Dubbo的时候接触的，所以ZooKeeper主要是用于：服务的容错、负载均衡、查找服务和管理服务，还可以选择其作为配置中心的集中式管理。 ZooKeeper的数据模型Session机制在了解ZooKeeper的数据模型之前，有必要了解ZooKeeper的Session机制 Session是指客户端和服务端之间会话。在ZooKeeper中是指一个客户端与ZooKeeper之间的一次长连接。客户端在启动时会与服务端建立一个Tcp连接。后续客户端可已通过这个连接发送消息给服务端，也可以监听服务端发送来的消息。客户端和服务端有一个心跳机制来维持和判断这个连接的有效性，可以通过Session中的sessionTimeout值来设置一个客户端的超时时间。同时当由于服务器原因或者客户端主动要求端口连接的时候，只要在超时时间内重新连接任一一台ZooKeeper机器，那么之前创建的 Session仍然有效。 和我们平常接触到HttpSession一样，每次创建一次会话，服务端都会为该客户端分配一个SessionId，该SessionId也是全局唯一的。 数据模型ZooKeeper的数据模型和我们经常使用的Unix/Linux的文件系统是类似的。 上图中我们可以比较明显看到和文件系统很像，实际它提供的操作API都有点类似。正确情况下，我们会在会根目录下创建一个自己项目的Znode。比如dubbo、kafka以便隔离数据。和我们创建文件夹的思路一样 znode 在ZooKeeper中每一个节点都称之为znode，它本身可以有子节点，也可以有数据。 每一个节点分为临时节点和永久节点，临时节点在客户端断开后消失。也就是Session超时 每一个节点都有各自的版本号。可以通过命令行来显示节点信息 没当节点的数据发生改变，那么该节点的版本号都会累加（乐观锁） 删除、修改节点时，如果版本号不匹配会报错（乐观锁） 由于ZooKeeper的数据都存在内存中，每个节点的数据不建议存储过大的数据。几K即可 节点也可以设置acl权限。可以通过权限来限制用户的操作（unix的文件权限） 这里需要注意znode分为临时节点和永久节点，临时节点在session关闭时会自动删除 watch机制ZooKeeper在针对每个节点的操作，都会有监督者（watcher），当监控对象znode发生了变化，则触发watcher事件，可以理解为监听器。zk中的watcher是一次性的，触发后立即销毁 父节点、子节点 增删改都能够触发watcher事件。 具体的watcher事件 创建节点触发， NodeCreated 修改节点触发，NodeDataChanged 删除节点触发，NodeDeleted 增加子节点触发，NodeChildrenChanged 删除子节点触发，NodeChildrenChanged 修改子节点不触发监听 这里我建议自己在命令行或者用代码api来自己体验下 ZooKeeper命令行了解基本的命令行，其实ZooKeeper的命令行并不多，这里只做简单介绍 执行./zkCli.sh即可打开命令行 查询命令ls path [watch] 查询目录 watch 设置子节点的watch事件 stat path [watch] 查询详细信息 watch 设置当前节点的watch事件（下面的watch都是类似的机制不在说明） 节点信息如下： cZxid 创建的id ctime 创建的时间 mZxid 修改的id mtime 修改的时间 pZxid 父节点的id cversion 子节点的version dataVersion 数据的version aclVersion 权限的version ephemeraOwner 0x0为永久节点，其他为临时节点（待定） datalength 数据长度 numChildren 子节点的大小 zxid:ZooKeeper状态的每一次改变, 都对应着一个递增的Transaction id, 该id称为zxid. 由于zxid的递增性质, 如果zxid1小于zxid2, 那么zxid1肯定先于zxid2发生创建任意节点, 或者更新任意节点的数据, 或者删除任意节点, 都会导致Zookeeper状态发生改变, 从而导致zxid的值增加. ls2 path [watch] 查询目录,同时展示节点的信息 get path [watch] 可以将目录的数据取出来 创建命令create [-s] [-e] path data acl -e 临时节点-s 顺序节点 在创建文件夹会在后面自动添加1开始的顺序 create /test/name hello-world 修改命令set path data [version] version 主要用于更新时的乐观锁 删除命令delete path [version] version 主要用于删除时的乐观锁 ZooKeeper的集群前面已经了解的ZooKeeper的概念，已经他能够为我们做什么。现在来了解一下ZooKeeper是怎么保证数据的统一性。以及自身集群的高可用。 ZooKeeper 中的角色ZooKeeper在实际生产环境中是推荐使用集群方式。 在ZooKeeper的集群中引入了Leader、Follower、Observer三种角色。如下图所示 ZooKeeper集群中的所有机器会通过Leader选举过程来选定一台成为Leader的机器。该Leader既可以为客户端提供读服务和写服务，但是Follower和Observer都只能提供读服务。Follower和Observer的唯一区别就是不参与Leader的选举过程，Observer仅仅是用提升服务的读取速度而存在的。因为Follower的无限增多也会影响选举的性能。 ZooKeeper的核心是原子广播，这个机制保证各个Server之间的同步。实现这个机制的协议叫Zab协议。Zab协议有两种模式：恢复模式（选主）和广播模式（同步） 当Leader服务器出现崩溃，重启，网络中断等异常情况时，Zab协议会进入恢复模式并选举出新的Leader服务 大致步骤如下： Leader election（选举阶段）：节点在一开始都处于选举阶段，只要有一个节点得到超半数节点的票数，它就可以当选准 leader。 Discovery（发现阶段）：在这个阶段，followers 跟准 leader 进行通信，同步 followers 最近接收的事务提议。 Synchronization（同步阶段）:同步阶段主要是利用 leader 前一阶段获得的最新提议历史，同步集群中所有的副本。同步完成之后 准 leader 才会成为真正的 leader。 Broadcast（广播阶段） 到了这个阶段，Zookeeper 集群才能正式对外提供事务服务，并且 leader 可以进行消息广播。同时如果有新的节点加入，还需要对新节点进行同步。 这里通过第一条的规则，所以ZooKeeper部署推荐为单数服务，假如3台机器。最大允许宕机一台。而四台机器也是最大允许宕机一台。所以并不推荐部署双数机器部署 ZooKeeper的读写机制 Zookeeper是一个由多个server组成的集群 一个leader，多个follower 每个server保存一份数据副本 全局数据一致 分布式读写 更新请求转发，由leader实施 Zookeeper的保证 更新请求顺序进行，来自同一个client的更新请求按其发送顺序依次执行 数据更新原子性，一次数据更新要么成功，要么失败 全局唯一数据视图，client无论连接到哪个server，数据视图都是一致的 实时性，在一定事件范围内，client能读到最新数据 Zookeeper的选举方式首先选举必须要半数通过才行 简单模拟一下： A提案说，我要选自己，B你同意吗？C你同意吗？B说，我同意选A；C说，我同意选A。(注意，这里超过半数了，其实在现实世界选举已经成功了。但是计算机世界是很严格，另外要理解算法，要继续模拟下去。) 接着B提案说，我要选自己，A你同意吗；A说，我已经超半数同意当选，你的提案无效；C说，A已经超半数同意当选，B提案无效。 接着C提案说，我要选自己，A你同意吗；A说，我已经超半数同意当选，你的提案无效；B说，A已经超半数同意当选，C的提案无效。 选举已经产生了Leader，后面的都是follower，只能服从Leader的命令。而且这里还有个小细节，就是其实谁先启动谁当头。 Zab协议和Paxos算法Paxos算法应该可以说是ZooKeeper的灵魂了。但是ZooKeeper并没有完全采用Paxos算法 ，而是使用ZAB协议作为其保证数据一致性的核心算法。另外，在ZooKeeper的官方文档中也指出，ZAB协议并不像Paxos算法那样，是一种通用的分布式一致性算法，它是一种特别为Zookeeper设计的崩溃可恢复的原子消息广播算法。 这里Paxos算法暂时没什么了解，可以参考一些文章和一些书籍了解 从Paxos到ZooKeeper 图解分布式一致性协议Paxos 实例详解ZooKeeper ZAB协议、分布式锁与领导选举 总结 ZooKeeper本身就是一个分布式程序。超过半数以上存活，ZooKeeper就能正常服务 ZooKeeper的数据保存在内中，保证低延迟和高吞吐量，也不建议在znode中保存过大的数据 ZooKeeper推荐使用在读多写少的场景写，上面我们可以到了ZooKeeper只有leader才能执行写操作，这样做确实天然的保证的其顺序性，但是也影响了性能 znode有临时节点和永久节点的区分，临时节点在Session关闭时删除。（Session的关闭时通过Session超时来决定的，如果断开后再超时时间连上来Session是会继续维持） ZooKeeper对于客户端主要提供两个操作：数据的增删改查和数据的监听服务 参考 https://www.cnblogs.com/raphael5200/p/5285583.html","tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"分布式锁","date":"2019-12-30T15:12:12.000Z","path":"2019/12/30/microservices/分布式锁/","text":"分布式锁前言分布式项目中必然而然的肯定会接触到分布式锁，相比诸如限流、熔断、分布式锁等其他技术。分布式锁在分布式项目是肯定会遇到的。因为其他技术可能在你的项目使用人数不多，业务简单而不需要。但是分布式锁在业务上基本是必须处理的。 目前分布式锁主流的实现方案有:redis分布式锁、ZooKeeper分布式锁两种。当然还有其他，比如基础关系型数据库来做分布式锁也有。这里只讲这两个。 redis分布式锁基本原理-RedLockredis分布式锁，在redis官方叫RedLock。其实现也主要分为两个阶段。 加锁-RedLockredis中加锁主要通过set命令来解决其中还用到了nx和px参数(在redis2.6.12版本后set命令增加了很多新的参数，所以理论上setnx、setex、psetex会被set命令取代，后续也不推荐使用以上命令，可能后续版本会被不推荐或者移除，具体可查看官网)来控制。 SET key my_random_value NX PX 30000 比如通过以上命令就可以获取锁，由于NX的特性只有在key不存在时才能设置成功保证了锁的独占性，而PX则保证了在锁的安全性，避免获取锁的客户端在崩溃后，锁能够自然释放掉。其中my_random_value可以设置为一个随机值，必须保证该值得全局唯一性 解锁-RedLock解锁的过程就可以直接使用DEL命令来解决，但是为了保证加锁和解锁是同一个客户端，所以我们要校验一下my_random_value是否正确。这里可以为了保证其原子性可以使用Lua脚本来完成 12345if redis.call(\"get\",KEYS[1]) == ARGV[1] then return redis.call(\"del\",KEYS[1])else return 0end 以上就是最基本的redis锁的原理 缺点这种锁肯定也有缺点。在redis主从哨兵的环境中。比如我们在主服务器获取了锁。此时主服务宕机。由于redis主从复制的异步特性，该key值没有同步到从服务器。并且完成了选举，此时第二个客户端就可能直接在新的主服务器获取到锁。所以就可能存在两个客户端同时获取到锁。 所以我们在核心业务的逻辑处理中要自己去保证被加锁的代码块的幂等性，不会因为分布式锁的问题而导致出现核心业务受损。 不知道有什么完美的解决方案，对redis内部的架构不大了解。待定！ RedissonRedisson是redis的一个java客户端。也是redis官网推荐的客户端（Spring-data-redis默认使用的Jedis），其中Redisson也对redis的分布式锁进行封装处理。比如对其支持可重复锁，公平锁等扩张，以便我们更好的使用Redis分布式锁。来简单看下Redisson的内部源码实现 这里首先要特别注意下由于Redisson的版本更迭比较快，我发现锁的内部实现代码。每个版本都有一些差异。基本原理都是一样的我用的SpringBoot所以版本也都一样。 Redisson Version : 3.11.3Redisson SpringBoot start Version ：3.11.3 Redisson分布式锁的基本使用Redisson的分布式锁使用和Java中的ReentrantLock的使用是一样的。 123456789101112@Autowiredprivate RedissonClient redissonClient;public void method() throws InterruptedException &#123; RLock lock = redissonClient.getLock(\"myKey\"); try &#123; lock.lock(); // 直接尝试获取锁 lock.tryLock(1, TimeUnit.MINUTES); // 也可以尝试获取锁 1分钟 &#125;finally &#123; lock.unlock(); &#125;&#125; 以上代码就是简单的lock使用。接下来来看下其源码实现 获取lock首先在了解过ReentrantLock的实现上，在看其实现就会简单很多。 先看下RLock lock = redissonClient.getLock(&quot;myKey&quot;);这句主要做了什么。 12345678910111213141516@Overridepublic RLock getLock(String name) &#123; return new RedissonLock(connectionManager.getCommandExecutor(), name); // 构造函数在下面&#125;public RedissonLock(CommandAsyncExecutor commandExecutor, String name) &#123; super(commandExecutor, name); // 命令执行器 this.commandExecutor = commandExecutor; this.id = commandExecutor.getConnectionManager().getId(); // 内部锁过期时间 30000毫秒 this.internalLockLeaseTime = commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(); this.entryName = id + \":\" + name; // redis的发布订阅 this.pubSub = commandExecutor.getConnectionManager().getSubscribeService().getLockPubSub();&#125; Redisson加锁的实现构造函数没有特别的，主要是获取Redis的连接的基本类。和一些默认的参数 lock获取完了，接下来看第二部加锁。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public void lock() &#123; try &#123; lock(-1, null, false); &#125; catch (InterruptedException e) &#123; throw new IllegalStateException(); &#125;&#125;private void lock(long leaseTime, TimeUnit unit, boolean interruptibly) throws InterruptedException &#123; long threadId = Thread.currentThread().getId(); // 获取当前线程id Long ttl = tryAcquire(leaseTime, unit, threadId); // 尝试获取锁 // 获取锁成功 if (ttl == null) &#123; return; &#125; // 如果获取锁失败，则订阅到对应这个锁的channel TODO 这一步还没有仔细看，待定 RFuture&lt;RedissonLockEntry&gt; future = subscribe(threadId); commandExecutor.syncSubscription(future); try &#123; while (true) &#123; ttl = tryAcquire(leaseTime, unit, threadId); // 再次尝试获取锁 // lock acquired if (ttl == null) &#123; break; &#125; // 锁获取失败，等待ttl超时后再尝试获取 if (ttl &gt;= 0) &#123; try &#123; getEntry(threadId).getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS); &#125; catch (InterruptedException e) &#123; if (interruptibly) &#123; throw e; &#125; getEntry(threadId).getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS); &#125; &#125; else &#123; if (interruptibly) &#123; getEntry(threadId).getLatch().acquire(); &#125; else &#123; getEntry(threadId).getLatch().acquireUninterruptibly(); &#125; &#125; &#125; &#125; finally &#123; // 取消订阅 unsubscribe(future, threadId); &#125;// get(lockAsync(leaseTime, unit));&#125; 接下跟下去详细看到尝试获取锁的方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344private &lt;T&gt; RFuture&lt;Long&gt; tryAcquireAsync(long leaseTime, TimeUnit unit, long threadId) &#123; if (leaseTime != -1) &#123; // 带有过期时间的获取锁 return tryLockInnerAsync(leaseTime, unit, threadId, RedisCommands.EVAL_LONG); &#125; // 没有带过期时间，则默认按30000毫秒来获取锁 RFuture&lt;Long&gt; ttlRemainingFuture = tryLockInnerAsync(commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(), TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG); // 如果没有获取到锁，则开启一个定时任务不断的去刷新该锁的过期时间 这里是一个看门狗的角色 ttlRemainingFuture.onComplete((ttlRemaining, e) -&gt; &#123; if (e != null) &#123; return; &#125; // lock acquired if (ttlRemaining == null) &#123; scheduleExpirationRenewal(threadId); &#125; &#125;); return ttlRemainingFuture;&#125;// 接着看tryLockInnerAsync方法// 他使用了lua脚本来设置的，而且使用的Hash结构&lt;T&gt; RFuture&lt;T&gt; tryLockInnerAsync(long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand&lt;T&gt; command) &#123; internalLockLeaseTime = unit.toMillis(leaseTime); return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command, // 锁不存在 hset获取锁，同时设置过期时间 \"if (redis.call('exists', KEYS[1]) == 0) then \" + \"redis.call('hset', KEYS[1], ARGV[2], 1); \" + \"redis.call('pexpire', KEYS[1], ARGV[1]); \" + \"return nil; \" + \"end; \" + // 锁已经存在 // 判断锁是否为当前线程，如果是对其值+1,同时再次设置时间(主要解决可重入锁的问题) \"if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then \" + \"redis.call('hincrby', KEYS[1], ARGV[2], 1); \" + \"redis.call('pexpire', KEYS[1], ARGV[1]); \" + \"return nil; \" + \"end; \" + // 都不是则直接返回锁的ttl \"return redis.call('pttl', KEYS[1]);\", // 下面是三个参数key[1] ARGV[1] ARGV[2] 分别是出传入key，时间，当前线程 // 这里可以去简单了解下lua的调用语法即可 Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId));&#125; 在了解key[1] ARGV[1] ARGV[2]是什么后很简单了。 实际上他为了一个map结构的数据。 key - 锁的名称filed - 随机字符串+线程ID 值为1value - 线程ID 会随着的递增来实现可重入锁 加锁基本就已经完成！ 接着来看下解锁 Redisson解锁的实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Overridepublic RFuture&lt;Void&gt; unlockAsync(long threadId) &#123; RPromise&lt;Void&gt; result = new RedissonPromise&lt;Void&gt;(); RFuture&lt;Boolean&gt; future = unlockInnerAsync(threadId); // 解锁的具体方法 future.onComplete((opStatus, e) -&gt; &#123; if (e != null) &#123; // 锁不存在异常 关闭前面开启的定时任务，抛出异常 cancelExpirationRenewal(threadId); result.tryFailure(e); return; &#125; // 解锁和持锁人不是同一个任务 抛出异常 if (opStatus == null) &#123; IllegalMonitorStateException cause = new IllegalMonitorStateException(\"attempt to unlock lock, not locked by current thread by node id: \" + id + \" thread-id: \" + threadId); result.tryFailure(cause); return; &#125; // 解锁成功 关闭前面开启的定时任务 cancelExpirationRenewal(threadId); result.trySuccess(null); &#125;); return result;&#125;// 接着直接看解锁的代码protected RFuture&lt;Boolean&gt; unlockInnerAsync(long threadId) &#123; // lua脚本 return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN, // 1. 判断锁是否等于当前线程，不等于则返回 \"if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then \" + \"return nil;\" + \"end; \" + // 2. 对锁进行递减 \"local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); \" + // &gt;0 则刷新一下过期时间 \"if (counter &gt; 0) then \" + \"redis.call('pexpire', KEYS[1], ARGV[2]); \" + \"return 0; \" + \"else \" + // 不是则删除key，并同时发布锁释放的消息 \"redis.call('del', KEYS[1]); \" + \"redis.call('publish', KEYS[2], ARGV[1]); \" + \"return 1; \"+ \"end; \" + \"return nil;\", Arrays.&lt;Object&gt;asList(getName(), getChannelName()), LockPubSub.UNLOCK_MESSAGE, internalLockLeaseTime, getLockName(threadId));&#125; Redisson的加锁和解锁基本完成。只需要简单的记住它所维护的map数据结构即可很好的记住它的原理 Redisson中的看门狗Redisson有一个看门狗的角色特别说明下，就是前面说的那个定时任务 首先通过前面的原理已经知道Redis在加锁的时候是会设置一下key的时间的。假如在持有锁的客户端在设置的时间内依然正在执行中，那么就很有可能锁被其他客户端拿到造成两个客户端同时获取到锁。为了解决这个问题才引入了看门狗这个角色。它主要监控获取锁的线程如果该线程一直在运行中，它可以为这个锁的时间来续约。默认是每次续约30000毫秒。 这个角色具体有兴趣可以自己看下源码。 ZooKeeper分布式锁ZooKeeper的分布式锁首先我们要知道ZooKeeper的基本原理和内存模型。具体可以看我的另外一篇文章，这里不多做介绍了！ 基本原理-Zookeeper加锁-ZooKeeper加锁主要是通过zookeeper来创建一个临时顺序节点。然后检查自己的节点是否为顺序中最小的那一个，如果不是则监听自己上一个顺序的节点等待被唤醒 实际就是类似维护了一个FIFO的队列，然后依次监听自己的上一个节点。就像链式结构一样 这里的临时节点可以保证，自己掉线后，由zookeeper来删除节点，最后通知下一个节点。保证链式不断。 解锁-ZooKeeper解锁就比较简单了。删除自己的节点即可。通过zookeeper的监听机制来通知其他节点 Curator既然Redis推荐Redisson，那么ZooKeeper肯定推荐的实现代码！这里推荐curator客户端。同时是基于ZooKeeper做一些开发。可推荐使用该客户端。因为原生客户端不大好用，比如由于ZooKeeper的watch绑定机制每次触发一次就会失效需要重新绑定。这里该客户端已经帮我们实现了动态绑定。避免我们写代码时忘记。详细使用可以自己查看官网了！ Curator的基本使用这里用的版本是2.8.0，其他版本的源码可能有些许出入。 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt;&lt;/dependency&gt; 这里简单看下使用的代码。非常简单。上面那部分代码可以集成在Spring中。统一使用CuratorFramework即可 12345678910111213141516ExponentialBackoffRetry retry = new ExponentialBackoffRetry(1000, 3);CuratorFramework framework = CuratorFrameworkFactory.builder() .connectString(\"192.168.72.253:2181,192.168.72.253:2182,192.168.72.253:2183\") .sessionTimeoutMs(50000) .connectionTimeoutMs(50000) .retryPolicy(retry) .namespace(\"duteliang\") .build();framework.start();InterProcessMutex interProcessMutex = new InterProcessMutex(framework,\"/zl/lock/name\");try &#123; interProcessMutex.acquire(); // 加锁&#125; finally &#123; interProcessMutex.release(); // 解锁&#125; Curator加锁的实现简单看下internalLock的内部实现 1234567891011121314151617181920private boolean internalLock(long time, TimeUnit unit) throws Exception &#123; // 获取当前线程 Thread currentThread = Thread.currentThread(); // 查询缓存是否已经获取到锁了 LockData lockData = threadData.get(currentThread); if ( lockData != null ) &#123; // 已经获取到锁，可重入锁 lockData.lockCount.incrementAndGet(); // lockCount +1 return true; &#125; // 获取锁 String lockPath = internals.attemptLock(time, unit, getLockNodeBytes()); if ( lockPath != null )&#123; // 获取锁成功，添加缓存 LockData newLockData = new LockData(currentThread, lockPath); threadData.put(currentThread, newLockData); return true; &#125; // 获取锁失败 返回false return false;&#125; 其中重点就是internals.attemptLock获取锁这个方法！继续看源码 1234567891011121314151617181920212223242526272829303132333435363738String attemptLock(long time, TimeUnit unit, byte[] lockNodeBytes) throws Exception &#123; final long startMillis = System.currentTimeMillis(); final Long millisToWait = (unit != null) ? unit.toMillis(time) : null; final byte[] localLockNodeBytes = (revocable.get() != null) ? new byte[0] : lockNodeBytes; int retryCount = 0; String ourPath = null; boolean hasTheLock = false; boolean isDone = false; while ( !isDone )&#123; isDone = true; try&#123; // 创建节点, 临时、顺序节点 ourPath = driver.createsTheLock(client, path, localLockNodeBytes); // 判断是否获取锁，同时阻塞自己。关键部分 hasTheLock = internalLockLoop(startMillis, millisToWait, ourPath); &#125;catch ( KeeperException.NoNodeException e )&#123; if ( client.getZookeeperClient().getRetryPolicy().allowRetry(retryCount++, System.currentTimeMillis() - startMillis, RetryLoop.getDefaultRetrySleeper()) )&#123; isDone = false; &#125;else&#123; throw e; &#125; &#125; &#125; if ( hasTheLock )&#123; return ourPath; &#125; return null;&#125;// 创建节点, 临时、顺序节点public String createsTheLock(CuratorFramework client, String path, byte[] lockNodeBytes) throws Exception &#123; String ourPath; if (lockNodeBytes != null) &#123; ourPath = client.create().creatingParentsIfNeeded().withProtection().withMode(CreateMode.EPHEMERAL_SEQUENTIAL).forPath(path, lockNodeBytes); &#125; else &#123; ourPath = client.create().creatingParentsIfNeeded().withProtection().withMode(CreateMode.EPHEMERAL_SEQUENTIAL).forPath(path); &#125; return ourPath;&#125; 这一步主要就是两步 创建临时顺序节点 循环对顺序节点和自己进行检查，来判断自己是否可以获取锁 接下来看第二部的代码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061private boolean internalLockLoop(long startMillis, Long millisToWait, String ourPath) throws Exception &#123; boolean haveTheLock = false; boolean doDelete = false; try &#123; // 这一步是实现可撤销锁的动作，具体还没有研究 if (revocable.get() != null) &#123; client.getData().usingWatcher(revocableWatcher).forPath(ourPath); &#125; // 循环获取锁 while ((client.getState() == CuratorFrameworkState.STARTED) &amp;&amp; !haveTheLock) &#123; List&lt;String&gt; children = getSortedChildren(); // 获取所有顺序节点，注意已经排序好了。从小到大 String sequenceNodeName = ourPath.substring(basePath.length() + 1); // 获取顺序节点的名称 // 这一步就不贴源码了，可以自己看下比较简单 // 主要判断当前节点是否为所有节点的第一个，如果是则获取到锁sTheLock=true, // 如果不是则获取到上一个顺序节点的名称 PredicateResults predicateResults = driver.getsTheLock(client, children, sequenceNodeName, maxLeases); if (predicateResults.getsTheLock()) &#123; // 获取到锁，返回 haveTheLock = true; &#125; else &#123; String previousSequencePath = basePath + \"/\" + predicateResults.getPathToWatch(); // 上一个顺序节点的完成名称 synchronized (this) &#123; try &#123; // 监听上一个节点、监听内代码在下面有贴。简单的notifyAll代码 client.getData().usingWatcher(watcher).forPath(previousSequencePath); if (millisToWait != null) &#123; // wait 开始阻塞线程等待 millisToWait -= (System.currentTimeMillis() - startMillis); startMillis = System.currentTimeMillis(); if (millisToWait &lt;= 0) &#123; doDelete = true; break; &#125; wait(millisToWait); &#125; else &#123; wait(); &#125; &#125; catch (KeeperException.NoNodeException e) &#123; // it has been deleted (i.e. lock released). Try to acquire again &#125; &#125; &#125; &#125; &#125; catch (Exception e) &#123; doDelete = true; throw e; &#125; finally &#123; if (doDelete) &#123; // 如果出现程序异常，则删除自己的节点。 deleteOurPath(ourPath); &#125; &#125; return haveTheLock;&#125;// 这里补充一下监听的代码。主要做了什么。// 主要通过 wait 和 notifyAll 的组合来处理private synchronized void notifyFromWatcher()&#123; notifyAll();&#125; 从代码可以看出，其主要逻辑 获取所有顺序节点 判断自己是否为顺序中最小的那个节点，是就获取锁 不是则获取自己上一个节点，然后watch它。等待唤醒 这里为了便于理解可以参考一下下面的逻辑图 Curator解锁的实现解锁就是比较简单了。就是删除节点。不多介绍。 12345678910111213141516171819202122public void release() throws Exception &#123; Thread currentThread = Thread.currentThread(); InterProcessMutex.LockData lockData = threadData.get(currentThread); if (lockData == null) &#123; // 当前没有获取到锁。解锁失败 throw new IllegalMonitorStateException(\"You do not own the lock: \" + basePath); &#125; int newLockCount = lockData.lockCount.decrementAndGet(); if (newLockCount &gt; 0) &#123; // 解锁成功 return; &#125; if (newLockCount &lt; 0) &#123; // 小于0，程序不正常。抛出异常 throw new IllegalMonitorStateException(\"Lock count has gone negative for lock: \" + basePath); &#125; try &#123; // 删除节点，触发监听器 internals.releaseLock(lockData.lockPath); &#125; finally &#123; // 删除缓存 threadData.remove(currentThread); &#125;&#125; 总结这里基本讲完了Redis和ZooKeeper分布式锁的原理和实现。当然了解原理后可以自己去滚轮子，但是要注意很多细节部分。推荐还是直接使用上面的框架。 那么Redis和ZooKeeper分布式锁，哪个好一点了。 我认为首先两者在性能上面都是完全能够在生产环境使用的，两者之间的主要区别在于： Redis分布式锁上面已经讲过在主从集群环境中，有一个缺点。就是有可能两个客户端同时获取到锁，ZooKeeper就不存在这种。这主要是两者设计理念所造成的。就是我们常说的CAP原则，ZooKeeper保证的是CP（容错性和一致性），而redis保证的是AP（容错性和可用性）。具体可以去了解一下CAP的设计原则。 ZooKeeper在锁等待时会阻塞线程，不需要通过循环来解决。这也是由于ZooKeeper天然提供watch机制所带来的好处 ZooKeeper由于CP所带来的强一致性，性能没有redis好，同时由于ZooKeeper的实现中频繁的删除添加节点也有影响。但是ZooKeeper并不慢，只是与Redis比较而言 所以如果能使用ZooKeeper我还是推荐使用ZooKeeper，但是ZooKeeper在项目中很多时候是作为注册中心来使用（比如dubbo），如果你的项目没有使用ZooKeeper，那么也可以使用Redis来做分布式锁，毕竟大部分项目都会使用Redis来做缓存。 参考文档redis官网set命令说明Distributed locks with Redis分布式锁之Redis实现curator-lock-document","tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"SpringBoot启动","date":"2019-10-12T01:58:51.000Z","path":"2019/10/12/framework/SpringBoot启动/","text":"SpringBoot启动Spring、SpringBoot启动属于是一个老生常谈的问题，以前整理过也比较碎片化。现重新进行一个整理。由于这个知识工作中用的不多，稍微深入一点太容易遗忘，作为一个长期更新的文档。有时间会更新一部分。同时由于两者对于Spring的启动有很大的共通性，所有主要介绍SpringBoot的启动。毕竟现在新项目基本很少采用Spring Framework了。 这里不想贴太多的源码讲解。不然我会觉得显得文档太长了 前言Spirng、SpringBoot的启动主要做了什么？ 这个问题大了说，只考虑Spring的话(如果包含容器部分，比如tomcat，还可能设计到Servlet等知识)，其实最主要就是加载Spring Bean。不管是xml、JavaConfig或者是直接申明的Bean，使用FactoryBean加载的Bean。所有的一切都是为了初始化Bean，初始化Bean的时候也就包括了我们启动需要的资源。 ServletSPI 机制在讲解SpringBoot的启动时，首先要了解SPI模式使用。这里我就不详细讲解，主要是一种服务发现机制。可以看看dubbo的开发者文档，因为dubbo中的很多实现也是基于这个来做的。 只不过SpringBoot的SPI有自己的实现和使用规则，原理都是JAVA自带的SPI类似的。 SpringBoot是在META-INF的spring.factories文件。 1234567# Application Context Initializersorg.springframework.context.ApplicationContextInitializer=\\org.springframework.boot.context.ConfigurationWarningsApplicationContextInitializer,\\org.springframework.boot.context.ContextIdApplicationContextInitializer,\\org.springframework.boot.context.config.DelegatingApplicationContextInitializer,\\org.springframework.boot.rsocket.context.RSocketPortInfoApplicationContextInitializer,\\org.springframework.boot.web.context.ServerPortInfoApplicationContextInitializer 格式就是上诉的这种方式。ApplicationContextInitializer的6个实现类，注意最后不能加,\\。 SpringBoot在使用SPI的时候一般还会对其进行重排序，我们将接口实现Ordered或者使用注解@Order来决定排序。因为在使用的时候是按顺序调用的。 SpringApplication123456@SpringBootApplicationpublic class WebBaseApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(WebBaseApplication.class,args); &#125;&#125; 上面这段代码就是SpringBoot常用的启动类，按方法分解为两部分，构造函数和执行函数。 先看下构造函数 构造函数123456789101112private List&lt;ApplicationContextInitializer&lt;?&gt;&gt; initializers;private List&lt;ApplicationListener&lt;?&gt;&gt; listeners;public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, \"PrimarySources must not be null\"); this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); this.webApplicationType = WebApplicationType.deduceFromClasspath(); // 这里使用SPI获取这两个接口的实现 setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass();&#125; 这里就使用SPI来获取ApplicationContextInitializer和ApplicationListener的实现。以便后面可以使用。除了SPI其实你可以在启动类中用代码去addXXX自己的实现类。也是可以的，毕竟SpringBootApplication也是将它存在一个私有变量中。 run方法接下来就是重点了，开始执行run方法。先看代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); configureHeadlessProperty(); // SPI获取SpringApplicationRunListener接口的实现类 SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); // 用户自定义 try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); // 初始化environment，也就是配置文件 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); Banner printedBanner = printBanner(environment); // 创建BeanFactory，这里使用了 AnnotationConfigServletWebServerApplicationContext 这个子类 context = createApplicationContext(); exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); // 准备上下文 prepareContext(context, environment, listeners, applicationArguments, printedBanner); // 刷新上下文 refreshContext(context); // 上下文刷新后 afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); &#125; listeners.started(context); // 用户自定义 callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); &#125; try &#123; listeners.running(context); // 用户自定义 &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); &#125; return context;&#125; 首先这里又来一个新的监听器SpringApplicationRunListener,也是通过SPI获取的。他其实是SpringBoot提供的一个接口，会在启动的调用该接口。我们可以通过该接口来在启动的各个阶段加入我们自己的逻辑。这个后面讲。 这里就没撒特别的了。 初始化environment 创建上下文AnnotationConfigServletWebServerApplicationContext 准备上下文 刷新上下文 中间穿插了SpringApplicationRunListener的影子 prepareContext 准备上下文1234567891011121314151617181920212223242526272829private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; context.setEnvironment(environment); postProcessApplicationContext(context); // 对应用上下文进行用户配置的额外处理 applyInitializers(context); // 执行ApplicationContextInitializer的初始化方法 listeners.contextPrepared(context); // 用户自定义 if (this.logStartupInfo) &#123; logStartupInfo(context.getParent() == null); logStartupProfileInfo(context); &#125; // 根据用户配置，对beanFactory设置一些参数 ConfigurableListableBeanFactory beanFactory = context.getBeanFactory(); beanFactory.registerSingleton(\"springApplicationArguments\", applicationArguments); if (printedBanner != null) &#123; beanFactory.registerSingleton(\"springBootBanner\", printedBanner); &#125; if (beanFactory instanceof DefaultListableBeanFactory) &#123; ((DefaultListableBeanFactory) beanFactory) .setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); &#125; if (this.lazyInitialization) &#123; context.addBeanFactoryPostProcessor(new LazyInitializationBeanFactoryPostProcessor()); &#125; // Load the sources Set&lt;Object&gt; sources = getAllSources(); Assert.notEmpty(sources, \"Sources must not be empty\"); load(context, sources.toArray(new Object[0])); listeners.contextLoaded(context); // 用户自定义&#125; 准备上下文，就是在整个上下文（ApplicationContext）、配置文件（Enviroment）等资源文件。 这里有个applyInitializers(context)就是执行最开始构造函数通过SPI拿到的ApplicationContextInitializer实现类。主要就是在刷新上下文指定一些自定义的代码。比如对配置文件的处理。 刷新上下文1234567891011121314151617181920212223242526272829303132333435363738394041424344@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125;catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125;finally &#123; resetCommonCaches(); &#125; &#125;&#125; 这里基本就是Bean的加载了。也就是IOC的主要部分。 找到一篇比较详细的文章推荐下! Spring-IOC ApplicationListenerApplicationListener是Spring Framework中的类。典型的观察者模式，我们可以在实现他对在Spring的启动，关闭等各个环节开启一个监听器。在设计模式中作为例子讲解一下 SpringApplicationRunListenersSpringApplicationRunListeners是SpringBoot中的类。它相当于SpringBoot开放的一个钩子函数。我们实现它，SpringBoot在启动的各个环节都会去执行该接口。我们可以在SpringBoot启动中加入自己的逻辑 实际应用其实看完上面的简单启动版本。其实有时候会在想实际开发中怎么用？ 下面简单说明一下 @EnableAutoConfiguration、Condition接口这两个其实才是实际框架集成到SpringBoot开发中用的最多的。 EnableAutoConfiguration具体实现可以看这篇文章，很不错的。EnableAutoConfiguration。 套用里面的一句话：@EnableAutoConfiguration也是借助@Import的帮助，将所有符合自动配置条件的bean定义加载到IoC容器，仅此而已！ 这才是我们需要的重点将我们定义的Bean加载到Spring 那Condition是干什么的了？ 1234@FunctionalInterfacepublic interface Condition &#123; boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata);&#125; Condition是Spring Framework中一直都存在的一个接口(具体哪个版本开始就不清楚了)。SpringBoot将它发扬光大了对其做了很多实现 该接口和@Bean，@Component配合使用来决定Bean是否需要加载 12345678910111213141516/*** 当配置 com.myConfig.one 有 true时则启动该Bean**/@Configuration@ConditionalOnProperty(value = \"com.myConfig.one\",havingValue = \"true\")public class Config &#123; /** * 存在当 OtherBean 存在Spring中就加载我们的Bean */ @Bean @ConditionalOnBean(OtherBean.class) public MyConfigBean myConfigBean() &#123; return new MyConfigBean(); &#125;&#125; 上面就是一个简单的例子。该注解就可以灵活的控制我们的Bean的加载情况。 到此SpringBoot启动先做了一个简单的介绍整理。主要是因为在我查看了自己以前写的文档后。发现过于碎片化和无脑贴代码。觉得没什么意义，还不如很多网上已有的文档好。所以就直接剔除了。文档中也贴了两个写的可以的文档。后面有时间在整理这部分！","tags":[{"name":"SpringBoot,Spring","slug":"SpringBoot-Spring","permalink":"http://yoursite.com/tags/SpringBoot-Spring/"}]},{"title":"SpringBoot打包分离资源文件","date":"2019-09-12T01:58:51.000Z","path":"2019/09/12/framework/SpringBoot打包分离资源文件/","text":"SpringBoot打包分离资源文件SpringBoot使用内置tomcat打包会非常简单，但是默认的SpringBoot的maven插件打包会将所有三方jar和配置文件打包成一个jar。但是在个人或者公司需要做一些小项目或者工具之类的，需要将三方jar包和配置文件分离。就需要利用maven插件来做打包了 SpringBoot打包先来看下SpringBoot的插件的打包代码 123456789101112131415&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.web.Application&lt;/mainClass&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;!--将三方jar打入jar中--&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 代码比较简单，不多介绍。 maven-jar-plugin我使用的assembly打包的方式，当然方法肯定不止一种，由于这种成功了，就没有去尝试其他了。 在使用这种插件的时候先要接触另外一种插件maven-jar-plugin，这个插件主要目的是将主项目打包成jar，而且指定jar的资源路径（实际就是配置_MANIFEST.MF文件_）。可以查看官网地址！有详细说明。链接直接看我的代码 12345678910111213141516171819202122232425&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;mainClass&gt;com.scxx.web.ScxxApplication&lt;/mainClass&gt; &lt;!--是否添加依赖--&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;!--路径项目前缀--&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;/manifest&gt; &lt;manifestEntries&gt; &lt;!-- MANIFEST.MF Class-Path 加入资源文件目录 --&gt; &lt;Class-Path&gt;./&lt;/Class-Path&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;excludes&gt; &lt;exclude&gt;application-*.yml&lt;/exclude&gt; &lt;exclude&gt;config/**&lt;/exclude&gt; &lt;exclude&gt;build/**&lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt;&lt;/plugin&gt; 插件主要做的事情就是打包主项目jar，指定class-path路径。同时过滤掉不想打入jar包的文件。这样jar包就ok了。我们看下META-INF资源文件写了什么 123456789101112Manifest-Version: 1.0Implementation-Title: webImplementation-Version: 0.0.1Archiver-Version: Plexus ArchiverImplementation-Vendor-Id: com.scxx.tool&#x2F;&#x2F; 注意的 .&#x2F; 实际就是上面配置的Class-pathClass-Path: .&#x2F; lib&#x2F;test-0.0.1.jar lib&#x2F;base-0.0.1.jar *** (lib文件很多，我过滤掉了)Created-By: Apache Maven 3.6.1Build-Jdk: 1.8.0_131Implementation-URL: https:&#x2F;&#x2F;projects.spring.io&#x2F;spring-boot&#x2F;#&#x2F;spring-bo ot-starter-parent&#x2F;kit&#x2F;webMain-Class: com.web.Application maven-assembly-plugin接下来开始使用maven-assembly-plugin插件做压缩和资源整理。官网链接 直接看代码 123456789101112131415161718192021&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;configuration&gt; &lt;!-- not append assembly id in release file name --&gt; &lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt; &lt;descriptors&gt; &lt;descriptor&gt;src/main/resources/build/release.xml&lt;/descriptor&gt; &lt;/descriptors&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 很普通，因为重点不是不在这里，主要在他指定的release.xml文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;assembly xmlns=\"http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.0 http://maven.apache.org/xsd/assembly-1.1.0.xsd\"&gt; &lt;id&gt;dist&lt;/id&gt; &lt;formats&gt; &lt;format&gt;tar.gz&lt;/format&gt; &lt;/formats&gt; &lt;includeBaseDirectory&gt;true&lt;/includeBaseDirectory&gt; &lt;dependencySets&gt; &lt;dependencySet&gt; &lt;!-- 排除自己的jar，因为这里我已经将他放在外面了--&gt; &lt;useProjectArtifact&gt;false&lt;/useProjectArtifact&gt; &lt;!-- 资源文件路径,注意和上面的lib路径对应 --&gt; &lt;outputDirectory&gt;lib&lt;/outputDirectory&gt; &lt;unpack&gt;false&lt;/unpack&gt; &lt;/dependencySet&gt; &lt;/dependencySets&gt; &lt;fileSets&gt; &lt;!-- 把项目相关的执行文件和说明文件，打包进压缩文件的根目录 --&gt; &lt;fileSet&gt; &lt;!-- 项目路径 --&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/main/resources/build&lt;/directory&gt; &lt;!-- 输出到zip的路径 --&gt; &lt;outputDirectory&gt;./&lt;/outputDirectory&gt; &lt;includes&gt; &lt;include&gt;*.txt&lt;/include&gt; &lt;include&gt;bin/**&lt;/include&gt; &lt;/includes&gt; &lt;/fileSet&gt; &lt;!-- 把项目相关的db文件，打包进压缩文件的根目录 --&gt; &lt;fileSet&gt; &lt;directory&gt;$&#123;project.basedir&#125;/db&lt;/directory&gt; &lt;outputDirectory&gt;./db&lt;/outputDirectory&gt; &lt;/fileSet&gt; &lt;!-- 把项目的基本配置文件，打包进压缩文件的根目录 --&gt; &lt;fileSet&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/main/resources&lt;/directory&gt; &lt;outputDirectory /&gt; &lt;includes&gt; &lt;include&gt;application-release.yml&lt;/include&gt; &lt;include&gt;application-business.yml&lt;/include&gt; &lt;include&gt;*.xml&lt;/include&gt; &lt;include&gt;*.properties&lt;/include&gt; &lt;/includes&gt; &lt;/fileSet&gt; &lt;!-- 把项目自己编译出来的jar文件，打包进压缩文件的根目录 --&gt; &lt;fileSet&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;outputDirectory /&gt; &lt;includes&gt; &lt;include&gt;*.jar&lt;/include&gt; &lt;/includes&gt; &lt;/fileSet&gt; &lt;/fileSets&gt;&lt;/assembly&gt; 此处主要理解fileSet的使用即可。将自己需要的文件要按路径打包压缩文件中! 需要注意的点都已经写在里面了。每个人可以根据自己的需求来制定自己的打包方式。 也可以参考这个项目的打包方式！链接","tags":[{"name":"SpringBoot,Maven","slug":"SpringBoot-Maven","permalink":"http://yoursite.com/tags/SpringBoot-Maven/"}]},{"title":"Bean的生命周期","date":"2019-09-12T01:58:51.000Z","path":"2019/09/12/framework/Bean的生命周期/","text":"Bean的生命周期前言讲解Bean的生命周期之前，要先了解一下IOC的基础原理。重点在Refresh方法。可以查看这个博客。我觉得写的很详细了。 我再对其做一个Bean的生命周期的补充 生命周期 构造函数 参数的注入，依赖注入 调用实现*Aware的接口的方法，顺序依次是：BeanNameAware、BeanFactoryAware、ApplicationContextAware 调用实现BeanPostProcessor接口的初始化方法 调用bean的初始化方法，initMethod（注解@PostConstruct） 调用接口InitializingBean的afterPropertiesSet方法 调用BeanPostProcessor的初始化之后的方法 Bean的销毁 基本就这些步骤 网上还有更多的详细步骤，有兴趣的可以自己去了解一哈，我有时间也会在总结一下 在我们使用Bean的时候。如果对Bean进行增强扩展。其实这些就已经足够。还有很多Bean的生命周期的调用Spring自己在处理的过程中的内部使用，不推荐我们去继承或者实现使用 实际使用其实在正常的情况第一步和第二步感觉已经足够，为什么还有后面这么多步骤？其实全部都是为了Bean的增强处理。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485@Component@Setter@Getter@ToString@Slf4jpublic class BeanDemo implements BeanNameAware, BeanFactoryAware, ApplicationContextAware , InitializingBean &#123; private BeanDemo2 beanDemo2; @Autowired public void setBeanDemo2(BeanDemo2 beanDemo2) &#123; this.beanDemo2 = beanDemo2; log.warn(\"BeanDemo 的注入！\"); &#125; private String name = \"name\"; private String age = \"age\"; static &#123; log.warn(\"BeanDemo的静态方法\"); &#125; &#123; log.warn(\"BeanDemo的构造方法\"); &#125; public BeanDemo() &#123; log.warn(\"BeanDemo的无参构造函数\"); &#125; @Override public void setBeanName(String name) &#123; this.name = name; log.warn(\"调用 BeanNameAware 方法,name=&#123;&#125;\",name); &#125; @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; log.warn(\"调用 BeanFactoryAware 方法,beanFactory=&#123;&#125;\",beanFactory); &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; beanDemo2 = null; log.warn(\"调用 ApplicationContextAware 方法,注入ApplicationContext \"); &#125; @Override public void afterPropertiesSet() throws Exception &#123; log.warn(\"调用 afterPropertiesSet 方法\"); &#125; @PostConstruct public void initMethod()&#123; log.warn(\"调用 initMethod 初始化方法 \"); &#125; @PreDestroy public void destroyMethod()&#123; log.warn(\"调用 destroyMethod 销毁方法 \"); &#125;&#125;@Component@Slf4jpublic class MyBeanPostProcessor implements BeanPostProcessor &#123; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; if(bean instanceof BeanDemo)&#123; log.warn(\"调用BeanPostProcessor 的初始化之前方法,Bean=&#123;&#125;\",bean.toString()); &#125; return bean; &#125; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; if(bean instanceof BeanDemo) &#123; log.warn(\"调用BeanPostProcessor 的初始化之后方法,Bean=&#123;&#125;\", bean.toString()); &#125; return bean; &#125;&#125; 这是一个普通的Bean。当我们创建这个Bean的时候日志打印 1234567891011WARN 7428 --- [ main] com.duteliang.webbase.bean.BeanDemo : BeanDemo的静态方法WARN 7428 --- [ main] com.duteliang.webbase.bean.BeanDemo : BeanDemo的构造方法WARN 7428 --- [ main] com.duteliang.webbase.bean.BeanDemo : BeanDemo的无参构造函数WARN 7428 --- [ main] com.duteliang.webbase.bean.BeanDemo : BeanDemo 的注入！WARN 7428 --- [ main] com.duteliang.webbase.bean.BeanDemo : 调用 BeanNameAware 方法,name&#x3D;beanDemoWARN 7428 --- [ main] com.duteliang.webbase.bean.BeanDemo : 调用 BeanFactoryAware 方法WARN 7428 --- [ main] com.duteliang.webbase.bean.BeanDemo : 调用 ApplicationContextAware 方法,注入ApplicationContext WARN 7428 --- [ main] c.d.webbase.bean.MyBeanPostProcessor : 调用 BeanPostProcessor 的初始化之前方法,Bean&#x3D;BeanDemo(beanDemo2&#x3D;null, name&#x3D;beanDemo, age&#x3D;age)WARN 7428 --- [ main] com.duteliang.webbase.bean.BeanDemo : 调用 initMethod 初始化方法WARN 7428 --- [ main] com.duteliang.webbase.bean.BeanDemo : 调用 afterPropertiesSet 方法WARN 7428 --- [ main] c.d.webbase.bean.MyBeanPostProcessor : 调用 BeanPostProcessor 的初始化之后方法,Bean&#x3D;BeanDemo(beanDemo2&#x3D;null, name&#x3D;beanDemo, age&#x3D;age) Aware接口Aware用的并不多,我再工作中并没有发现使用的时候。有使用场景的时候在补充吧 BeanPostProcessor 接口BeanPostProcessor就是一个比较实用的东西你可以拿它去修改一些框架的Bean，如果Bean有时候并不如满足你的要求，但是你又不想去重写他整个部分只为修改一小部分（尤其是一些框架内部的bean）。你就可以使用它来对Bean进行增强处理你可以拿它去对你的Bean添加代理，对Bean做一些监控。 初始化方法 @PostConstruct也比较实用，你可以在启动的时候对你的Bean做一些资源处理。可以在此加入你的逻辑 afterPropertiesSet这个倒是用的不多，可以去检验Bean的参数? FactoryBean的使用这里稍微讲解一下FactoryBean的部分 FactoryBean顾名思义其实就是一个Bean。可以理解为一个特殊的Bean。注意别把他和BeanFactory搞混了就行 直接看看这货的使用 12345678910111213@Component // 可以不写该注解，直接在xml中配置public class MyFactoryBean implements FactoryBean&lt;MyBean&gt; &#123; @Override public MyBean getObject() throws Exception &#123; // 加入你的复杂的逻辑判断 return new MyBean(); &#125; @Override public Class&lt;MyBean&gt; getObjectType() &#123; return MyBean.class; &#125;&#125; 上面就是FactoryBean的使用,可以理解为他相当于实际Bean的代理类。 这货有什么实际用处了？本人在开发中，其实主要在XMl时代是个神器可以解决很多普通xml无法解决的问题。 举个例子：比如我在实际开发中，redis,mongodb的连接。尤其环境的不一致，公司开发由于机器不够可能用的单机。云上生产环境肯定是用了副本集或者分片。在连接代码肯定是不一样的。xml很难去解决这个问题（当然你在xml中开启注解扫描，直接使用@Configuration也可以，为了统一性。有时候不会做）。 这时候FactoryBean的作用就来了。你可以在XMl中配置FactoryBean。在其代码中直接通过对配置的参数自动选择使用单机或者副本集或者分片等等。 不过现在新项目采用SpringBoot以后xml基本被抛弃，使用代码创建Bean本身灵活性就很大，这种问题也不存在。后面倒是没怎么用过了。","tags":[{"name":"Spring,Bean","slug":"Spring-Bean","permalink":"http://yoursite.com/tags/Spring-Bean/"}]},{"title":"J.U.C","date":"2019-05-20T01:58:51.000Z","path":"2019/05/20/javabase/J.U.C/","text":"J.U.C前言首先我们要编写一些代码的例子，以便更好测试和理解哪个操作是线程安全，那些操作不是线程安全的。 12345678910111213141516171819202122232425262728293031323334@Slf4jpublic class Test &#123; // 请求总数 private static int requestTotal = 8000; // 线程总数 private static int threadTotal = 200; // 共享变量 private static int count = 0; public static void main(String[] args) throws InterruptedException &#123; ExecutorService threadPool = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(requestTotal); for (int i = 0; i &lt; requestTotal; i++) &#123; threadPool.execute(() -&gt; &#123; try &#123; semaphore.acquire(); add(); semaphore.release(); &#125; catch (Exception e)&#123; log.error(\"error\",e); &#125; finally &#123; countDownLatch.countDown(); &#125; &#125;); &#125; countDownLatch.await(); threadPool.shutdown(); log.info(\"共享变量数：&#123;&#125;\",count); &#125; // 主要关注的点 private static void add()&#123; count++; &#125;&#125; 该代码就是利用多线程执行 count++ 操作！很明显执行后的结构肯定是小于八千的，主要原因是count++这个操作并非原子性。多线程会影响其count的取值。 Atomic 包Atomic包里面有很多基本类型的线程安全类，当我们把上诉代码中的Int缓存AtomicInteger此代码就是线程安全的。看下源码 12345678910111213public final int getAndIncrement() &#123; return unsafe.getAndAddInt(this, valueOffset, 1);&#125;public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125;public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); 关键代码是native修饰，并不是由java实现。但是从这简单的代码，我第一次看到就猜到了这不就是乐观锁么。事实也确实如此。compareAndSwapInt 方法就是在作比较成功就交换的动作。一只不断尝试。所以Atomic包下的类基本就是利用这种CAS无锁操作。来实现并发支持。理论上这种循环都是很快就能够完成的。比锁的效率要高。不建议在有大量更新的情况下使用。更多的是作为一些状态的标记来使用。 其他的Atomic包下的类有： AtomicLong LongAdder ActomicBoolean ActomicReference ActomicIntegerFieldUpdate 更新某个类的字段 字段必须是volatile ActomicStampReference CAS的ABA的问题 就先不多做介绍了。 并发集合我们都知道我们常用的ArrayList、LinkedList都不是线程安全的，并发情况下会出现数据BUG。那有哪些List是线程安全的了？ Vectorvector并不是J.U.C下的包。但是他确实是一个线程安全的集合和ArrayList一样，底层都是由数组实现。不同的是它的基本所有的方法都加了synchronized加锁，以保证线程的安全性。 Stackstack也不是J.U.C下的包。他是一个线程安全的集合。和Vector一样也是加了synchronized保证线程安全性。stack是一个算法中常用的模型。基于FILO原则。 CopyOnWriteArrayListJ.U.C下的并发类，简单看下它的部分内部源码 123456789101112131415161718public boolean add(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; // copy一个新数组 Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; setArray(newElements); return true; &#125; finally &#123; lock.unlock(); &#125;&#125;public E get(int index) &#123; return get(getArray(), index);&#125; 重点在add方法，首先利用ReentrantLock这种独占锁保持线程安全。在add操作时，先copy一份数组出来，更新后在写会原数据。这种方式保证了读取的效率。读数据不会受写数据的影响。但是这中缺点也比较明显。 保证了最终一致性，但是实时性比较差 由于每次更新都要copy一次整个数据，对于数据量偏大的数据容器引起YGC、FGC的操作。 所以这个比较适合数据量不大，读多写少，而且实时性安全不是很严格的情况下。该数据实际使用的情况不多。 CopyOnWriteArraySet底层使用了CopyOnWriteArrayList来实现，唯一的区别就是List和Set的区别。 ConcurrentSkipListMap、ConcurrentSkipListSetConcurrentSkipListMap底层采用了一种跳表的数据形式，实际是一种链表。底层通过CAS的方式保证了线程安全性。 ConcurrentSkipListSet底层使用了ConcurrentSkipListMap来实现注意两者都不支持null的处理，同时对于addAll等批量操作，不能保证安全性。只能保证单数据操作的安全性 ConcurrentHashMap用的最多的并发类，可以查看其他文档。 其他Collections.synchronizedXXX:collection、List、Set、Map 我们可以通过Collections工具类来直接生成一个线程安全的集合，实现比较简单，通过synchronized关键字来保证线程安全","tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"Servlet","date":"2019-05-12T04:32:42.000Z","path":"2019/05/12/javabase/Servlet/","text":"Servlet前言Servlet在我工作中其实是一个每天都要接触的东西，毕竟是搞Java Web的。但是Tomcat、Spring MVC都已经帮我们做好了所有的东西，所以我们在用的时候，只是简单的写了Class，再写个注解就能使用了。所以属于比较容易遗忘的东西。这里就简单的讲解一下什么是Servlet，我个人认为也没有必要弄得非常深和全面(其实我也没有那个技术)，毕竟别人都滚好轮子了。我们用就是了，但是还是要理解一下其中原理。遇到问题也好查找原因。 什么是ServletServlet在Java Web开发中每天打交道的一个东西，它是什么？简单的说我认为它只是一个规范、一个接口，就像BeanFactory一样定义的规范类似。 123456789101112131415package javax.servlet;import java.io.IOException;public interface Servlet &#123; void init(ServletConfig var1) throws ServletException; ServletConfig getServletConfig(); void service(ServletRequest var1, ServletResponse var2) throws ServletException, IOException; String getServletInfo(); void destroy();&#125; 这就是Servlet的接口规范。其实很简单。依次说下每个方法的作用，我们就能了解Servlet是干什么的 init 初始化servlet 其实就是我们经常配的&lt;init-params&gt;，有了他我们才能知道这个Servlet对应哪个请求，找准自己的定位 getServletConfig 不讲了，没撒用，获取配置 service 处理请求， getServletInfo get方法没撒好说的 destory 销毁servlet 所以上面可以看出其实Servlet主要就规范了3个东西，接受请求、处理请求、响应请求。 那么Servlet这么简单。我们就实现一个Servlet是不是就可以用了？不行！这只是一个规范，所以还需要一个容器来管理Servlet。请求来了帮我们找到指定的Servlet。比如我们最最最常用的Tomcat（所以Tomcat也可以说是一个Servlet容器）。其实这里有点像Spring和Bean之间的关系。 HttpServlet讲了Servlet，那我们到底怎么使用。这里就引入了HttpServlet。毕竟Servlet这个接口太抽象了。我们不好用，所以他就有了模板类，就是我们经常会用到的模板方法模式。 1234567891011121314151617/** * @author: zl * @Date: 2019/12/9 23:39 */public class MyServlet extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException&#123; super.doGet(req, resp); &#125; @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; super.doPost(req, resp); &#125;&#125; HttpServlet实现了Servlet接口（中间还有一个抽象类，你可以理解它对Servlet又做一步实现的扩充），也把能做的事情都做了。留了doXXX接口给我们实现。让我们写自己的逻辑请求。上面就是我们常用的Servlet的实际写法。其实我们还要配置ServletConfig，不然这个Servlet都不知道自己是谁。比如可以在Web.xml中配置初始化的基本参数 至于请求是怎么进入Servlet的，这个到SpringBoot的启动里面讲一下，因为SpringBoot是内嵌Tomcat，所以看源码比较好看一点。而且好理解。 Servlet生命周期Servlet的生命周期很多时候面试可能都会去问，其实当简单看懂上面的说明后加上一些工作经验和猜测，就可以简单的猜出它的生命周期了。 客户端发起Http请求 容器去解析请求 创建Servle,注意这里其实是有Tomcat容器肯定不会每次都初始化，在第一次初始化会将这个Servlet保存在内存中，下次请求就可以直接使用了 调用Init方法，初始化请求 调用Servce方法，响应请求 输出响应信息，一般会帮我们封装成Response 调用destory()方法，由于Servlet会驻留在内存中。一般情况是tomcat容器关闭会去调用destory方法 Jsp和Servlet说到Servle还是必须说明一下Jsp。Jsp是在Servlet后面出现的。主要是因为Servlet在对返回Html页面的时候不是很友好，所以才有了Jsp。所以我们可能都知道Jsp其实就是一个Servlet 其实我们在访问一个Jsp的时候，它在第一次访问的时候。会将Jsp编译成一个Java类，这个类是继承也是HttpServlet的。 比如自己可以做个测试环境做一个简单jsp 123456789101112&lt;%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\"pageEncoding=\"UTF-8\"%&gt;&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; hello world&lt;/body&gt;&lt;/html&gt; 当我们调用通过url获取jsp页面时，其实已经讲Jsp编译成Class，实际上就是执行Servlet 123456789101112131415161718192021222324252627282930313233343536373839package org.apache.jsp.WEB_002dINF.jsp;import javax.servlet.*;import javax.servlet.http.*;import javax.servlet.jsp.*;public final class hello_jsp extends org.apache.jasper.runtime.HttpJspBase implements org.apache.jasper.runtime.JspSourceDependent, org.apache.jasper.runtime.JspSourceImports &#123; // 省略 public void _jspService(final javax.servlet.http.HttpServletRequest request, final javax.servlet.http.HttpServletResponse response) throws java.io.IOException, javax.servlet.ServletException &#123; try &#123; javax.servlet.jsp.JspWriter out = null; response.setContentType(\"text/html; charset=UTF-8\"); pageContext = _jspxFactory.getPageContext(this, request, response, null, true, 8192, true); _jspx_page_context = pageContext; application = pageContext.getServletContext(); config = pageContext.getServletConfig(); session = pageContext.getSession(); out = pageContext.getOut(); _jspx_out = out; out.write(\"\\r\\n\"); out.write(\"&lt;!DOCTYPE html&gt;\\r\\n\"); out.write(\"&lt;html lang=\\\"en\\\"&gt;\\r\\n\"); out.write(\"&lt;head&gt;\\r\\n\"); out.write(\" &lt;meta charset=\\\"UTF-8\\\"&gt;\\r\\n\"); out.write(\" &lt;title&gt;Title&lt;/title&gt;\\r\\n\"); out.write(\"&lt;/head&gt;\\r\\n\"); out.write(\"&lt;body&gt;\\r\\n\"); out.write(\" hello world\\r\\n\"); out.write(\"\\r\\n\"); out.write(\"&lt;/body&gt;\\r\\n\"); out.write(\"&lt;/html&gt;\"); // ... &#125;&#125; 我只断断续续的贴了一部分。其中HttpJspBase的基本关系：public abstract class HttpJspBase extends HttpServlet implements HttpJspPage，可以看到其实也是继承了HttpServlet，那他是怎么把html给客户端的，可以看到实际也就是通过write()写出去。其实和我们一样的。 不过Jsp相对于Servlet好用的一点是，它内置了9个对象：out、session、response、request、config、page、application、pageContext、exception我们可以直接在jsp中使用（其实我用的很少，主要也就获取一个项目根路径，然后el表达式基本够用）。 Jsp也就基本结束了 题外话，为了测试演示了一下，用SpringBoot搞一个Jsp环境好多坑，也确实SpringBoot其实对Jsp不怎么友好，如果没有前后端分离想使用页面，还是推荐它默认的thymeleaf","tags":[{"name":"JavaEE,Servlet","slug":"JavaEE-Servlet","permalink":"http://yoursite.com/tags/JavaEE-Servlet/"}]},{"title":"HashMap","date":"2019-04-25T01:58:51.000Z","path":"2019/04/25/javabase/HashMap/","text":"HashMap1. 何为hash简单的说hash可直接理解为一个数组，区别在于其下标是通过hash算法来算出来的，一个好的算法能够使数据分配的更加均匀。但是不管多好的算法。总会发生不同的数据算出一样的hash值，这样就会发生hash碰撞，hashMap的解决办法是在发生hash碰撞的地址继续通过链式结构来组装，这其实就是HashMap的基本结构了！ 2. HashMap中的基本变量本次主要以JDK8为准，和7的区别主要是引入了红黑树 1234567891011121314151617181920// 默认初始化容器大小,必须是2的倍数static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16// 最大的容器大小static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;// 扩容因子static final float DEFAULT_LOAD_FACTOR = 0.75f;// 结构体static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125;&#125; 首先了解一下它的结构体，里面存了一个hash，key实际就HashMap中的key，value也就是我们实际的数据，next是为了链式而准备的。 3. 初始化123456789101112131415161718public HashMap(int initialCapacity, float loadFactor) &#123; // 校验数据准确性 if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; // 获取调整容器的大小阈值，initialCapacity*loadFactor this.threshold = tableSizeFor(initialCapacity);&#125;public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted&#125; 初始化的过程比较简单，就是计算和校验了需要准备的参数，其中有个扩容因子，可以理解为当实际数据达到容器的多少比例就需要扩容处理。 4. 添加数据123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// 实际存放transient Node&lt;K,V&gt;[] table;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // table为null，则初始化 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 由于n为2的整数，所以n-1的二进制尾数都为1 // 这里实际是获取hash在n的数组内的下标 if ((p = tab[i = (n - 1) &amp; hash]) == null) // 该下标没有数据，则新增 tab[i] = newNode(hash, key, value, null); else &#123; // 该下标有数据，说明发生hash碰撞 Node&lt;K,V&gt; e; K k; // 判断key值是否相等，相等直接替换value if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 判断p是否是TreeNode是则走红黑树的判断 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 走正常的链表判断 else &#123; for (int binCount = 0; ; ++binCount) &#123; // 将数据添加到链表结尾 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); // 这里要判断链表转红黑树的阈值，默认是8 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // key只相等，说明是update操作 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // 这里e!=null表示是update操作，这里没有做任何处理 // 留了个钩子函数，给LinkedHashMap做继承使用 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 如果数量大于容器阈值，则需要扩容 if (++size &gt; threshold) resize(); // 同样没有处理，给LinkedHashMap做继承使用 afterNodeInsertion(evict); return null; &#125; 走完代码！逻辑其实已经很清晰。还需要看一下resize主要是怎么扩容的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; // 表示容器已经初始化，试一次扩容操作 if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; //到达容器的极限 threshold = Integer.MAX_VALUE; return oldTab; &#125; // 未到达容器极限，数量乘以2 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; // 这里表示初始化时，给了自定义的参数,阈值已提前算好 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; // 初始化是默认的，直接取默认的 else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 上面只解决了newCap没有处理newThr，这里处理 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; // 上面代码已经解决了初始化和扩容参数问题，这里主要解决实际的数据迁移问题 if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; resize其实就是对数据的初始化和2倍扩容操作。 5. Remove操作1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; // 判断下标是否存在数据 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; // 下标中的第一个数据就相等 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; // 数据可能在链表或者红黑树中，在深入查找 else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; // 找到数据，对数据进行删除 if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null; &#125; 6. 结语通过对HashMap的基本操作理解，其实可以大概知道了HashMap的基本元素！数组+链表or红黑树。红黑树由于还没有研究，所以这里我直接跳过了，有需要可以在去深入理解一下。所以这里知道对HashMap而言，增加性能的方法有： 减少Hash碰撞 减少扩容操作 其实1不是很好操作，对于2需要的仅仅只是在创建Map的时候对于已知的数据大小，要尽量给出初始化的容器大小，避免频繁的自动扩容！","tags":[{"name":"Map","slug":"Map","permalink":"http://yoursite.com/tags/Map/"}]},{"title":"Java线程和线程池","date":"2019-04-19T01:58:51.000Z","path":"2019/04/19/javabase/线程和线程池/","text":"线程和线程池1. 何为线程简单的理解就是一个进程里的细致划分，我们正常的软件只会占用一个进程，但是为了更好的榨干cpu的性能，可以将进程分为多个线程，实际处理工作的是线程！ 2. 线程的状态 java中线程的状态 新建状态：调用new，还没有启动开始代码执行！ 就绪状态：对象已经准备好，但是还没有开始执行run 运行状态：执行run方法后，程序正常执行 阻塞状态：线程因为各种原因进入阻塞，而让出CPU资源的状态 sleep程序调用Thread.sleep(xx)后，线程释放CPU资源，但是没有释放锁资源 wait程序调用wait后，线程释放CPU资源和锁资源，注意wait只有在锁内才能调用，否则会抛出IllegalMonitorStateException异常！ IO or 调用其他同步方法其他原因就是程序在调用IO或者其他同步的方法时，调用者处于休眠状态时！ 死亡状态：线程进入死亡状态正常执行完成后进入死亡状态或者在遇到异常后中断程序进入死亡状态 3. 线程池池这技术，我们会经常遇到，比如jdbc会遇到连接池，目的都是差不多，主要是更好的管理这些单位的创建和死亡。线程池也是为了更好管理线程的创建与销毁动作！ 3.1 ThreadPoolExecutorjava中自带线程池的线程池有四种：可缓存线程池，定长线程池，单线程池，还有一个支持简单定时调度的线程池。这些线程池不需要记。通过源码其实可以看到他们都是调用通一个构造函数。所以我们只需要理解这个构造函数的原理即可，很多团队也都是直接调用该构造函数来创建线程池，这样可以直观的理解创建线程池的参数 123456789101112131415161718192021public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 实际的创建线程池的构造函数，简单说明一下每个参数的含义: corePoolSize 核心线程数量 maximumPoolSize 最大线程数量 keepAliveTime 线程活跃保存时间，如果创建的线程大于核心线程数量的清除动作！ unit 上面这个参数的时间单位 workQueue 阻塞队列，存放等待的队列 threadFactory 线程工厂，用来创建线程 handler 驳回策略 12345678910111213141516171819202122public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); // 1.如果当前活跃线程小于核心线程数量，直接执行线程 if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; // 2. 尝试将线程加入阻塞队列，如果加入成功！后面再次检查了一下是否加入成功！ if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // 3. 再次尝试启动队列,但是不能超过最大线程数 else if (!addWorker(command, false)) reject(command); &#125; 从上面的逻辑，已经可以了解核心参数的基本含义了！源码y有更加深入的了解可以查看这篇文章了, 链接 参数的基本逻辑为： 判断核心线程数，小于则启动线程 判断阻塞队列， 判断最大线程数 驳回策略 3.2 阻塞队列阻塞队列BlockingQueue，Java提供了几种实现！ ArrayBlockingQueue 基于数组的有界阻塞队列，FIFO LinkedBlockingQueue 基于链式的有界阻塞队列，FIFO SynchronousQuene 不存储元素的阻塞队列，每次插入都要等上一个节点移除 PriorityBlockingQuene 具有优先级的无界阻塞队列 LinkedBlockingQueue比ArrayBlockingQueue在插入删除节点性能方面更优，但是二者在put(), take()任务的时均需要加锁，SynchronousQueue使用无锁算法，根据节点的状态判断执行，而不需要用到锁，其核心是Transfer.transfer(). 3.3 驳回策略驳回策略，Java也提供了几种实现！ AbortPolicy 直接抛出异常，默认 CallerRunsPolicy 用调用者所有线程，执行任务 DiscardOldestPolicy 丢弃阻塞队列中最靠前的任务，来执行该任务 DiscardPolicy 不处理 我们也可以自己实现RejectedExecutionHandler接口，主要做一些记录日志操作。 3.4 自带线程池其实有了上面的这些基础，在看看Java默认提供的几种线程池，就很容易理解了，也就是利用这些参数的使用来封窗了一些比较常用的线程池。 3.4.1 newFixedThreadPool12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 定长线程池，特点是核心线程数和最大线程数相等，采用链式阻塞队列，大小为Integer.MAX_VALUE基本为无界队列，所以驳回策略基本失效，最大线程池理论也失效！ 3.4.2 newSingleThreadExecutor123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 单线程池，特点是核心线程数和最大线程数都为1，采用链式阻塞队列和上面一样。所以驳回策略也失效，但是同时只能进行一个线程在运行中，所以叫单线程池。 3.4.3newCachedThreadPool12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 缓存线程池，核心线程数为0，最大线程数最大值。由于核心线程数为0以及采用了SynchronousQueue这种不存储元素的队列，所以实际上线程会一直无限量的在运行，吞吐量会比较大，但是高峰期会对性能有影响。但是由于核心线程数为0，所以线程池也会定时清理无用线程！该线程池是需要谨慎使用的一种。","tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"锁、AQS","date":"2019-04-18T01:58:51.000Z","path":"2019/04/18/javabase/锁、AQS/","text":"锁、AQS1. 前言在实际开发中在多线程中保证其安全性，其实我们用的最多的是互斥锁，也就是synchronized关键字，我们更多的是考虑怎么降低锁的颗粒性，以及锁持有的时间。其次就是ReentrantLock，该类和synchronized功能几乎一样，唯一的特点是它比synchronized更加灵活。 2. ReentrantLock2.1 初始化直接来看源码 123456/***构造函数中可以看出，可以选择创建公平锁和非公平锁*/public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 2.2 非公平锁的加锁1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public void lock() &#123; // 加锁 sync.lock();&#125;static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; final void lock() &#123; // CAS判断如果是0则更新成1,这里变量state是AbstractQueuedSynchronizer抽象类中的变量 // 这里我们需要知道state表示该锁一共有加锁的次数，0表示锁处于空闲状态 if (compareAndSetState(0, 1)) // 更新成功，保存持有锁的线程 setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125;abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = -5179523762034025860L; abstract void lock(); final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); //获取当前线程 int c = getState(); // 获取state if (c == 0) &#123; // state=0，表示锁处理空闲状态时，直接持有锁即可 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; // 锁已被人持有，判断锁持有人是否为当前线程 // 是则state+1，否表示加锁失败 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false; &#125;&#125;abstract class AbstractQueuedSynchronizer &#123; public final void acquire(int arg) &#123; // 尝试获取锁（子类实现）获取锁失败则将线程加入等待队列中 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; private Node addWaiter(Node mode) &#123; // 加入等待队列 Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node; &#125; private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // 等待队列为空，创建一个头部队列 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; // 等待队列不为空，将当前node加入到队列的尾部 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; &#125;&#125; 非公平的加锁的已经完成，其中有一系列的CAS操作，我们要知道CAS操作是无锁的，处于线程安全的。基本所有更新的操作都是安全的！ 其中还有一个点，比如在nonfairTryAcquire和addWaiter中，明明已经有了整个处理的逻辑为什么还要在外层加一层判断，这里主要是为了性能考虑。当某个状态可直接快速的决定逻辑的走向，所有可以优先判断快速处理。不必走整个完整的逻辑。当然这里牺牲了一些代码的可读性！ 这一步结合简单的图来在整体了解一下加锁过程 剖析出来整体是比较清晰的。 2.3 AQS中的等待队列这里的加入等待队列，比较重点。在AQS里面。维护了一个等待队列，来保存等待的线程。从上面代码可出实际头部节点在初始化的时候是没有保存线程的。实际的线程是在第二个队列中。接下来看一下acquireQueued方法做了什么？ 12345678910111213141516171819202122232425262728// 跳出等待队列 final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; // 死循环 final Node p = node.predecessor(); // 获取前驱节点 // 如果前驱节点=头部节点， if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; // 判断是否要阻塞当前线程 /** 在AQS的等待队列中，只有前置是SIGNAL状态才能开始等待。 */ // 阻塞当前线程 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 简单的看出，首先是一个死循环，一是如果前驱节点是头部节点，再次尝试获取锁。成功则自己设为头部节点。（特点注意这里在已经在加入等待队列时，已经获取到锁了）。如果不是，则尝试加入队列同时阻塞自己。看下shouldParkAfterFailedAcquire方法，检查是否允许进入阻塞。 123456789101112131415161718192021222324private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * 这个状态标识，可以正常挂靠在这里 */ return true; if (ws &gt; 0) &#123; /* * 这个状态，会一直往前找，找到一个不属于CANCELLED的node */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * 其他节点会默认为 SIGNAL * 我们这里会先走这个流程，在走第一条分支。标识可以正常挂靠 */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 所以这里队列其实是可以通过状态来标识自己是否有需要被唤醒。我们这个AQS的实现。暂时没有用到这个，一直是SIGNAL状态。注意这里的死循环，简单说就是一个线程在尝试加入队列的同时，也在不断的尝试获取锁。比如发现前置节点是SIGNAL则开始阻塞线程。等待执行线程的唤醒。然后又继续重复尝试获取线程，尝试加入队列。 2.4 非公平锁的解锁123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public void unlock() &#123; sync.release(1);&#125;abstract static class Sync extends AbstractQueuedSynchronizer &#123; protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; // 获取state-1 // 当前线程不是持有锁的线程，直接抛出异常 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; // state-1 = 0 表示解锁成功 free = true; setExclusiveOwnerThread(null); &#125; setState(c); // state-1 != 0 表示是可重入锁，减了一层， return free; &#125;&#125;abstract class AbstractQueuedSynchronizer &#123; public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; // 判断队列是否为null if (h != null &amp;&amp; h.waitStatus != 0) // unparkSuccessor(h); return true; &#125; return false; &#125; private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread); &#125;&#125; 解锁过程比较简单。主要是从队列的尾部像前找，找到对接近队列头部的节点切状态正确的节点，将其唤醒。 2.5 整体流程看下来其实可能比较模糊，我们最后看一下流程图！ 最后文字在讲述一下基本的逻辑 线程A lock，state=0，将state=1，获取到锁，此时队列为null 线程B lock，尝试获取锁失败，加入队列，由于队列为null，先初始化一个head，把自己放在head后面。 线程B 准备休眠，开始死循环，检查自己的前置节点是不是head，是则尝试获取一下锁。失败的话。开始判断自己是否可以休眠。 检测自己的前置节点，是否为SIGNAL标识，是则直接执行休眠 前置节点为CANCELLED标识(代码是&gt;0)，将自己的node往前推，删除前置节点，直到不是CANCELLED标识 其他标识，将标识直接改成SIGNAL标识，这里线程B会先进入第三条规则，因为其前置节点是空节点，没有设标识。在进去第一条规则。可以挂靠。 线程C lock，尝试获取锁。 线程A 此时放开锁，唤醒了线程B，线程B开始尝试获取锁，注意此时线程C也在尝试获取锁，结果被线程C获取到，同时将自己设为head。而线程B又在死循环中进入休眠。等待下次唤醒。 最后根据流程图看会比较简单了。终于为什么叫非公平锁，其实可以看出来了！就是在获取锁的时候，首先会尝试获取一下锁。不行再加入到队列。这里就存在一些竞争关系，实际就是我上面文字描述的4、5两步骤。但是并不是完全非公平的，只在新成员加入队列前会有尝试获取锁的机会。进入队列中是按公平的策略来的。 2.6 公平锁公平锁和非公平锁区别不大。 12345678910111213141516171819202122232425262728293031static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; acquire(1); &#125; /** * Fair version of tryAcquire. Don't grant access unless * recursive call or no waiters or is first. */ protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false; &#125; &#125; 首先lock的时候，没有了提前去判断state的状态，毕竟判断了也不可能给你随便加入。然后就是尝试获取锁，这里有个方法 hasQueuedPredecessors 这个方法主要是判断队列中是否有在等待中的线程。所以这里解决了根本原因的，就是公平锁在第一次锁的时候会判断一下的队列的情况。这样就解决了上面说到的非公平锁的不公平性。 2.7 Condition 用法3. Semaphoresemaphore信号量，可以控制并发访问的线程个数。可以在需要访问限制中使用，比如一些连接池、限流的场景。当然很多高并发的限流工具，我们会优先采用现成的，自己写的不多。所以用的频率不高。但是自己写写测试代码倒是用的挺多。来看下基本用法 123456789101112public static void main(String[] args) throws InterruptedException &#123; // 初始化，同时允许的并发个数 Semaphore semaphore = new Semaphore(100); try &#123; // 获取一个许可 semaphore.acquire(); semaphore.tryAcquire(); //尝试获取一个许可 &#125;finally &#123; // 释放一个许可 semaphore.release(); &#125; &#125; 简单看下源码,也是通过继承AQS模板来实现， 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class Semaphore&#123; // 初始化，维护AQS的state变量， // 也分公平和非公平模式和ReentrantLock类似的实现，这里只贴非公平锁的代码 public Semaphore(int permits, boolean fair) &#123; sync = fair ? new FairSync(permits) : new NonfairSync(permits); &#125; // 获取许可 public void acquire() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; abstract static class Sync extends AbstractQueuedSynchronizer &#123; // 以非公平方式，尝试获取凭证 final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; int available = getState(); // 获取state int remaining = available - acquires; // 如果 remaining &gt;= 0 表示凭证够，后面的CAS是保证数据的正确性 // &lt; 0 凭证不够，直接返回 if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125; &#125; &#125;&#125;public abstract class AbstractQueuedSynchronizer&#123; public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; // 获取许可 if (Thread.interrupted()) throw new InterruptedException(); // 尝试获取，调用实现类 nonfairTryAcquireShared // 这里的不公平地方也在这里。来了什么都不管先尝试一下。 // 所以这个实现在公平锁肯定会加入判断队列的情况而非公平锁就不会去判断队列的情况 if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg); &#125; // 开始阻塞线程 也和ReentrantLock类似 private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.SHARED); // 将自己加入队列 boolean failed = true; try &#123; for (;;) &#123; // 死循环 final Node p = node.predecessor(); // 获取前置节点 if (p == head) &#123; int r = tryAcquireShared(arg); // 尝试获取凭证 if (r &gt;= 0) &#123; // 获取成功，将自己设为头部节点 setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; // 开始检查自己是否可以加入队列， if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125;&#125; 简单看一下和ReentrantLock其实比较类似。利用好AQS的模板效果。重点在于state的维护和队列的使用。这些都是AQS内部已经建好的。需要是掌握时机即可。 4. CountDownLatch CyclicBarrier两者都可以保证线程的优先级，也就是在多线程中能够保证线程的执行顺序，比如在拆分计算的时候，可以保证某些计算先做，某个后做。 4.1 CountDownLatch主要体现在一个线程等待多个线程的效果比如下面的例子，导游等待多个同学，只有当同学全部到了以后就可以触发了 1234567891011121314151617public static void main(String[] args) &#123; // 初始化，同时允许的并发个数 ExecutorService service = Executors.newFixedThreadPool(3); CountDownLatch countDownLatch = new CountDownLatch(2); service.execute(() -&gt; &#123; log.info(\"A同学在路上\"); countDownLatch.countDown(); &#125;); service.execute(() -&gt; &#123; log.info(\"B同学在路上\"); countDownLatch.countDown(); &#125;); service.execute(() -&gt; &#123; countDownLatch.await(); log.info(\"2个同学到了，开车旅游\"); &#125;); &#125; 4.2 CyclicBarrier表达的是多个线程互相等待，然后一起进行的操作！比如下面的旅游，但是没有老师了，自发约定地点。我这里的例子可能不是很合理。但是区别还是很明显的。 1234567891011121314public static void main(String[] args) &#123; CyclicBarrier cyclicBarrier = new CyclicBarrier(2); ExecutorService service = Executors.newFixedThreadPool(3); service.execute(() -&gt; &#123; log.info(\"A同学到了约定地点\"); cyclicBarrier.await(); // 等待 log.info(\"可以走了\"); &#125;); service.execute(() -&gt; &#123; log.info(\"B同学到了约定地点\"); cyclicBarrier.await(); // 等待 log.info(\"可以一起走了\"); &#125;);&#125; 4.3 区别CyclicBarrier的计数器是可以重置的，CountDownLatch 不可以。CyclicBarrier是表示多个线程互相等待，然后互相一起走。CountDownLatch 表达的是一个线程等待多个线程，然后这一个线程就可以走了。CyclicBarrier的API方法比较CountDownLatch 更加丰富一些，可以自己查看一下！ 5. FutureTaskfutureTask也可以实现线程的等待。这里简单的看一下代码的使用！ 123456789101112131415public static void main(String[] args) throws ExecutionException, InterruptedException &#123; ExecutorService service = Executors.newFixedThreadPool(3); Future&lt;String&gt; submit1 = service.submit(() -&gt; &#123; log.info(\"助手1:切肉！\"); return \"切好的肉\"; &#125;); Future&lt;String&gt; submit2 = service.submit(() -&gt; &#123; log.info(\"助手2切青椒\"); return \"切好的青椒\"; &#125;); log.info(\"主厨准备其他东西\"); String s = submit1.get(); String s1 = submit2.get(); log.info(\"青椒肉丝出锅\"); &#125; 比如青椒和肉丝其实也可以有两个人一起切。最后主厨就在准备好调料后，就在等待主材料。这三种都是可以同步执行的，如果主厨比较快。那么就会通过get方法，获取需要东西，然后开启等待。","tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"Java集合","date":"2019-04-14T01:58:51.000Z","path":"2019/04/14/javabase/集合/","text":"集合1. 概述java中的集合主要指的Collection和Map两个接口大类主要区别在于Collection是单列集合，Map是键值对的集合相对于数组而言除了更加强大API使用，还有对通过对数据结构的灵活使用可以更加贴合实际的生产使用 2. Collectioncollection接口主要包括两大类List和Set区别在于List中的元素是可重复，Set中的元素是不可重复的 2.1 ListList 主要有ArrayList，LinkedList，两者之间的主要区别在于数据结构的不同导致的性能的差异性。 2.1.1 ArrayListArrayList基于数组来实现 特点： 查询快，能够根据下标快速定位数据 插入数据慢，设计到数据的移位等问题。 2.1.2 LinkedListLinkedList基于链表来实现 特点： 查询慢，因为不知道数据的具体存放地址 插入数据块，因为设计到更少的数据迁移 这两个集合特点和区别也非常鲜明，主要是数组和链式来决定的。 数组实际是一个整齐排放的数据结构，所以当你知道数据的下标，便能直接获取数据。如果不知道下标，其实查询效率和链表也没什么区别了。而当你插入数据的时候，除非插入到坐标尾部，否则都会涉及到数据的迁移以保证其规则性（如果数组满了，申请扩容也会迁移） 链表 相对于数组也比较清晰了。实际每个数据体都存放了上个节点和下个节点的地址，所以查询会慢，而对数据的插入基本不会涉及数据的迁移，所以插入效率会比较高 2.2 SetSet 主要使用的HashSet,LinkedHashSet，TreeSet 2.2.1 HashSet，LinkedHashSet其中HashSet，LinkHashSet在了解HashMap后会比较好理解，因为他的底层也是实际利用HashMap和LinkHashMap来实现的 HashSet利用HashMap的key的唯一性来实现HashSet LinkedHashSet利用LinkedHashMap的key值唯一性，以及其顺序性来实现 2.2.2 TreeSetTreeSet底层采用二叉树实现，效率高，元素有序且唯一。如果排序需求可以考虑使用。 3.1 Mapmap在实际使用中最典型的可能就是HashMap，也是必须要掌握的，具体可查询另外一篇详细文档！ 3.1.1 LinkedHashMapLinkedHashMap继承了HashMap，和它的区别在于HashMap的存放规则是随机的。而LinkedHashMap在其基础上了做了一个链表的结构。实际就是HashMap.Node&lt;K,V&gt; 有加了一个before和after属性。 LinkedHashMap的使用时，有两种排序规则，一种是按插入排序和访问排序 插入排序： 调用put时来排序，也是默认的 访问排序： 每次get会改变其排序，get的数据会自动到尾部 3.4 CollectionsCollections.unmodifiableXXX:collection、List、Set、Map通过Java自带的工具类来创建一个只读的集合。底层主要是对get操作直接抛出异常来保证其只读行。 Guava.ImmutableXXX:Collection、List、Set、Map有可以通过GuavaCache下的Immu..包来保证只读性。实现都差不多。","tags":[]},{"title":"SpringMVC的一次调用","date":"2019-04-12T01:58:51.000Z","path":"2019/04/12/framework/SpringMVC的一次调用/","text":"SpringMVC的一次调用前言SpringMVC其实我觉得可讲的还不是很多，但是曾经面试最喜欢的问的就是SpringMVC的一次调用过程，不知道现在是什么情况。 SpringMVC的作用首先我们要知道SpringMVC是以Servlet为基础的一个框架，属于web层的MVC框架，用来替代Servlet来做http请求的响应和处理。通过它我们可以通过几个简单的注解就可以高效的处理请求和返回数据。 前面容器已经讲过Servlet，在看SpringMVC就比较简单了。我们知道Servlet主要用来对请求的初始化，处理已经返回数据。假如我们没有Servlet那么我们对每个请求都要不厌其烦的去配置对每个请求的拦截，然后对每个请求做自己业务处理。SpringMVC就将其做了简化动作以便我们高效开发。 SpringMVC的调用过程直接抛出一个网上随处可找的图，然后直接说明结果，最后简单讲解一下其大致思路 上图算是找到的一张比较完整的图。实际我也不会记得这么详细，大致的过程为 客户端发起请求，进入DispatcherServlet DispatcherServlet通过传入的url找到对应的Handle(即Controller) 最后调用其逻辑 获取到返回值后，经过视图解析器，返回Html（如果是ajax就直接返回数据） 这里的逻辑我写的比较简单，不想弄得太复杂 DispatcherServletDispatcherServlet是SpringMVC的核心功能，本质是一个Servlet。这个Servlet逻辑处理比较多。但是也好理解。直接看代码了。不做配置说明了 看代码之前先要了解一下其的类的关系图 可以明显的看到他还是集成了Servlet,而且是HttpServlet只不过他又加了几层封装（每次看Spring的代码，其实都可以猜到了，它的风格就这样）,那么如果肯定去找doService方法咯 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990@Overrideprotected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; //---忽略代码-- try &#123; doDispatch(request, response); &#125; finally &#123; // ---忽略代码--- &#125;&#125;protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; // 对文件的处理 processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // 获取handler，通过RequestMappingHandlerMaping获取 mappedHandler = getHandler(processedRequest); if (mappedHandler == null) &#123; noHandlerFound(processedRequest, response); return; &#125; // 获取Handler适配器 HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // 对浏览器请求的特殊处理 String method = request.getMethod(); boolean isGet = \"GET\".equals(method); if (isGet || \"HEAD\".equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; // 实际调用Handle的方法，返回封装个后的ModelAndView mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; applyDefaultViewName(processedRequest, mv); mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception ex) &#123; dispatchException = ex; &#125; catch (Throwable err) &#123; // As of 4.3, we're processing Errors thrown from handler methods as well, // making them available for @ExceptionHandler methods and other scenarios. dispatchException = new NestedServletException(\"Handler dispatch failed\", err); &#125; // 跳转到指定页面（跳转到指定的视图） processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception ex) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; catch (Throwable err) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(\"Handler processing failed\", err)); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; // Instead of postHandle and afterCompletion if (mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125; else &#123; // Clean up any resources used by a multipart request. if (multipartRequestParsed) &#123; cleanupMultipart(processedRequest); &#125; &#125; &#125;&#125; 基本源码也就这里了。 这里讲的不很仔细，后面再补充!","tags":[{"name":"SpringMVC,Spring","slug":"SpringMVC-Spring","permalink":"http://yoursite.com/tags/SpringMVC-Spring/"}]},{"title":"反射","date":"2019-04-12T01:58:51.000Z","path":"2019/04/12/javabase/反射/","text":"反射前言java的反射机制是指在运行时获取类的属性和方法。并且能够动态修改属性和调用方法。 在日常开发中尤其是在集成代码，简化代码的时候，我们经常会遇到不能在编译时就能获取属性。这时候我们会用反射来解决这个问题。 首先要明确的是：通过来反射获取属性和调用方法，肯定比直接用代码硬编码要慢。所以反射我们需要谨慎的使用，尤其是当自己编写的方法可能会频繁调用的时候。就需要考虑加入缓存或者考虑是否不使用反射来达到效果。 对于反射为什么会慢，其实我自己也没有深刻理解。这篇stackoverflow有些讨论。 大致可以看到是: 反射相对直接调用，JVM并不是很好的去对其优化。 必须发现正在调用/创建的所有内容 参数需要重新包装成数组，同时还要捕获异常InvocationTargetException 反射并不慢，相对网络传输、解析xml等其他耗时行为。 反射的基本使用java中反射的api相对比较简单。这里简单写一下常用的 1234567891011121314151617181920212223242526272829303132333435363738394041public class main &#123; public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException, InstantiationException, NoSuchMethodException, InvocationTargetException &#123; Class&lt;ReflectBean&gt; clzss = ReflectBean.class; // 1. 创建实例 ReflectBean reflectBean = clzss.newInstance(); // 2. 字段操作 // 获取字段 (只能获取public的,但是可以获取从父类继承过来的public属性) Field name = clzss.getField(\"pubName\"); Field[] fields = clzss.getFields(); // 获取字段 (获取当前类的所有字段，但是获取不到父类继承来的属性) Field name1 = clzss.getDeclaredField(\"name\"); Field[] declaredFields = clzss.getDeclaredFields(); // 获取字段属性 // 在获取private属性时，必须将该属性设为true才能直接get。你可以选择通过get，set方法来获取 name1.setAccessible(true); name1.set(reflectBean,\"反射设置的name\"); String str = (String)name1.get(reflectBean); System.out.println(str); // 3. 方法操作 // 获取方法 这里和field一样操作。不多赘述 Method method = clzss.getMethod(\"method\"); Method[] methods = clzss.getMethods(); Method priMethod = clzss.getDeclaredMethod(\"priMethod\", String.class); Method[] declaredMethods = clzss.getDeclaredMethods(); // 调用方法 Object invoke = method.invoke(reflectBean); priMethod.setAccessible(true); // 下面是私有的方法，也要加上这句 Object string = priMethod.invoke(reflectBean, \"string\"); System.out.println(invoke); System.out.println(string); System.out.println(reflectBean); &#125;&#125; 以上就是如此了。反射暂时没有发掘有撒可扩充的。有实际的比较好的实际使用再来更新。","tags":[]},{"title":"并发基础","date":"2019-04-11T01:58:51.000Z","path":"2019/04/11/javabase/并发基础/","text":"并发基础并发BUG的源头并发的原因现在主流是三种，原子性、可见性、有序性。本质乃是计算机CPU、内存之间的问题。问题本身很复杂，才疏学浅只简单的讲下理解的。目的就是为了有个基本的概率，可以更好的理解并发。 可见性一个线程对共享变量的修改，其他线程是否能够立即看到，就称为可见性。至于为什么会有这个问题，其实主要是因为缓存的问题导致的。在计算机中CPU并不是直接操作内存里面的数据，每个CPU本身也会缓存，CPU只会操作自己缓存的数据，然后CPU缓存和内存进行交互。多线程的情况就会出现缓存和主内存的数据不一致的问题！ CPU缓存和内存的关系图其实在Java的内存模型中，也会出现这种情况，在下图中可以明显看到。JAVA的引用对象，每个线程在修改对象数据时，并不是直接修改内存的数据，而是每个线程都保存了一份实际内存的数据备份。这样也会可见性的问题 原子性原子性的日常理解是：某个单位已经到了最小不可拆分的单位。就说明这个单位具有原子性。在编程中其实也比较好理解，比如 count += 1 就不具备原子性。因为我们都知道他是分为几步完成的 123将count的数据从内存中取出 --&gt; 1count+1 --&gt; 2将count放回内存中 --&gt; 3 这三部在执行过程中。都会出现中断或者多线程的原因其他线程中途也对count进行了操作。这一步操作并不是最小单位。 有序性有序性，就是程序按代码编写的逻辑执行。但是实际情况下程序并不是按代码编写的逻辑执行的，为什么会这样？主要原因是编译优化，比如程序中： int a=1; int b = 2; 正常应该先做a，在做b。但是实际情况并不是确定，有可能b先做，但是在编译优化并不会影响程序在单线程中执行，多线程就不确定了。 在单例模式中的双重检查有一个很经典的例子。 Java内存模型理解以上三种特性后，想要避免多线程的BUG，比如可见性是缓存导致的，我们就禁用缓存。有序性是编译优化导致的，我们就禁用编译优化。这样做确实可以减少很多并发的BUG，但是会导致性能大减。 合理方案应该是按需优化。 现代计算机体系大部是采用的对称多处理器的体系架构。每个处理器均有独立的寄存器组和缓存，多个处理器可同时执行同一进程中的不同线程，这里称为处理器的乱序执行。在Java中，不同的线程可能访问同一个共享或共享变量。如果任由编译器或处理器对这些访问进行优化的话，很有可能出现无法想象的问题，这里称为编译器的重排序。除了处理器的乱序执行、编译器的重排序，还有内存系统的重排序。因此Java语言规范引入了Java内存模型，通过定义多项规则对编译器和处理器进行限制，主要是针对可见性和有序性。 Happens-BeforeHappens-Before 原则主要是Java推出的一些规范。 程序次序规则：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确地说，应该是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。 管程锁定规则：一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是同一个锁，而”后面”是指时间上的先后顺序。 volatile变量规则：对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的”后面”同样是指时间上的先后顺序。 线程启动规则：Thread对象的start()方法先行发生于此线程的每一个动作。 线程终止规则：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread.join（）方法结束、Thread.isAlive（）的返回值等手段检测到线程已经终止执行。 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted()方法检测到是否有中断发生。 对象终结规则：一个对象的初始化完成(构造函数执行结束)先行发生于它的finalize()方法的开始。 volatilevolatile 关键可以对象的可见性以及指令重排序，以为volatile修饰的变量在操作时会通过内存屏障来禁止指令重排序。而且其修饰的关键字在使用变量和更新变量时都会更新内存中的变量缓存和提交线程中的变量缓存。所以解决了可见性的问题，但是无法解决原子性的问题 主要使用用于标记状态、doubleCheck finalfinal关键字申明的对象是无法再修改的，也就天然的保证了其可见性的问题，只有查看而没有修改。（注意final修饰引用对象时，对象内部的引用对象也是可以修改的）。 锁锁主要是解决其原子性的问题。后续会详细讲解","tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"JVM之GC","date":"2019-03-15T01:58:51.000Z","path":"2019/03/15/jvm/JVM之GC/","text":"JVM之GC垃圾回收算法讲垃圾回收算法之前，先简单说一下两个算法依据 引用计数算法： java在运行时，一个对象如果有被引用则对象实例+1，引用失效-1，垃圾回收时，找到引用为0的回收即可，这种算法缺点比较明显，当对象互相引用时，则无法回收到。JVM没有采用该算法2. 可达性分析算法相对于引用计数算法，有根节点的概念，通过根节点的对象引用链，来找到不需要回收的对象。最终无法到达的对象即为需要回收的对象。跟节点如何选取：类加载器、Thread、虚拟机栈本地变量、static成员、常量引用、本地方法栈等等都是root节点的选择对象 标记清除将需要回收的对象进行标记，最后进行清除 特点：效率一般且会产生碎片 标记整理和标记清除类似，先标记需要回收的对象，不同之处在于清除对象后，会将现有的对象进行整理来解决碎片化的问题。但是比较耗时 复制算法复制算法会将内存按容量分为两块区域，每次只使用其中一块。回收垃圾时，将保留的对象直接复制到另外一块区域，同时直接清除本区域的对象。 特点：简单高效、空间利用率低 分带垃圾回收分带垃圾回收是将内存分类，Young区和old区，每个分区使用不同的回收算法。来高效的利用回收算法的优缺点。JVM中也是使用了改逻辑来处理的。Young区：复制算法Old区：标记清除或标记整理 垃圾收集器串行收集器Serial开启参数：-XX:+UseSerialGC 串行收集器属于一种传统的收集器。内存很小时会使用，比如一些嵌入式的程序中会使用该收集器。 特点是：简单高效，效率高。但是必须暂停其他所有的工作线程 并行收集器Parallel开启参数：-XX:+UseParallelGC,-XX:+UseParallelOldGCservice模式默认的收集器 并发收集器ConcurrentCMS：-XX:+UseConcMarkSweepGC -XX:+UseParNewGC G1：-XX:+UseG1GC JVM常用的收集器和优化点以JDK8为例，可以查看官网：HotSpot虚拟机垃圾收集优化指南 并行收集器并行收集器(也称为吞吐量收集器)是相对于串行收集器而言的，区别在于收集垃圾时，使用的多线程来收集。收集时也是需要暂停应用程序的。 设置线程数 -XX:ParallelGCThreads=&lt;N&gt;核心数N小于8时等于N，大于8时为5/8。 也可以用上诉方式调优 在并行收集器中使用了一种自动调整的方法，JDK推荐使用以下3个参数来帮助收集器来调整性能。 以下排名有先后顺序 最大垃圾回收暂停时间 -XX:MaxGCPauseMillis=&lt;N&gt; 吞吐量 -XX:GCTimeRatio=&lt;N&gt; 比如配置99，则表示收集时间 1/1+N 为1% 内存占用 -Xmx 通过这三个参数，收集器会自动优化程序，达到以上的要求。 Generation Size Adjustment同时我们还可以调整分区的动态适应参数来帮助其更好的优化 -XX:YoungGenerationSizeIncrement=&lt;Y&gt; young generation增长比率 默认为20 -XX:TenuredGenerationSizeIncrement=&lt;T&gt; tenured generation增长比率 默认为20 -XX:AdaptiveSizeDecrementScaleFactor=&lt;D&gt; 缩小因子，如果增长比率是X，那么缩小比率就是 X / D, 默认为4，也就是5% 如果collector决定在启动的时候就增长generation，那么会在原增长比率上有一个增加量，这个增加量会随着gc次数越来越低，这个主要是为了提高启动的性能。缩小时没有增加量。 如果最大pause time的目标没有达成，那么会一次自会缩小一个generation。如果两个generation都达不到目标，那么pause time较长的那个会先被缩小 如果throughput的目标没有达到，那么两个generation区域都会被增加。然后按照比例扩展，比如young generation的gc时间占到总gc时间的25%，而增长比率是20%，那么实际会增长5%。 CMSCMS适合在响应时间要求比较的服务器上使用， G1","tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"JVM之内存模型","date":"2019-03-14T01:58:51.000Z","path":"2019/03/14/jvm/JVM之内存模型/","text":"JVM之内存模型JVM 内存模型以及分区栈区栈分为java虚拟机栈和本地方法栈 java虚拟机栈是线程私有，生命周期和线程相同。 每个方法都会创建一个栈帧，用于存放局部变量表，操作栈，动态链接，方法出口等。每个方法被调用，直到执行完毕，对于着一个栈帧的入栈到出栈的过程。 方法区 （也可以叫永久代）方法区也叫作永久代，主要存放虚拟机加载的类信息，常量和静态变量等数据。 JDK8中叫元空间(MetaSpace)，移除出JVM。直接使用在内存中 程序计数器当前线程执行的行号指示器，在循环，分支，跳转，以及多线程之间交易都会使用这个，它是线程私有的。 堆区堆是所有线程共享的，唯一目的就是存放对象实例 堆区分为新生代和老年代，新生代又分为三个区域，比例为8:1:1 新生代采用的复制算法来回收对象。 老年代采用标记清除算法和标记-整理法 堆区参数有：-Xms 堆最小值 -Xmx 堆最大值， 一般情况下，可以讲堆内存设置到物理内存的百分之八十。两者相等可以避免内存的跳动新生代堆参数有：-XX:NewSize 新生代最小值，-XX:MaxNewSize 新生代最大值永久代大小调整：-XX:MaxPermSize JDK8已经取消了，转移到外部内存中-XX:MaxTenuringThreshold 设置新生代对象转到老年代需要经过多少次垃圾回收 类加载类加载的过程 加载获取二进制字节流，同时将静态存储结构转换为方法区数据结构 验证主要验证字节流的格式规范 准备此阶段主要分配变量比如static的变量，分配类变量的初始值。只有final才会被分配的正确的值 解析 初始化这一步主要初始化静态代码块，构造函数，父类的初始化等 使用 卸载 由GC来处理 双亲委派模型：Bootstrap ClassLoader、ExtensionClassLoader、ApplicationClassLoader。类加载器按照层次，从顶层到底层，分为以下三种： （1）启动类加载器（BootstrapClassLoader） 这个类加载器负责将存放在JAVA_HOME/lib下的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机识别的类库加载到虚拟机内存中。启动类加载器无法被Java程序直接引用。 （2）扩展类加载器（ExtensionClassLoader） 这个加载器负责加载JAVA_HOME/lib/ext目录中的，或者被java.ext.dirs系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器 （3）应用程序类加载器（ApplicationClassLoader） 这个加载器是ClassLoader中getSystemClassLoader()方法的返回值，所以一般也称它为系统类加载器。它负责加载用户类路径（Classpath）上所指定的类库，可直接使用这个加载器，如果应用程序没有自定义自己的类加载器，一般情况下这个就是程序中默认的类加载","tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"JVM调试命令","date":"2019-03-12T01:58:51.000Z","path":"2019/03/12/jvm/JVM调试命令/","text":"JVM调试命令参数类型标准参数-help，-version X参数-Xint 解释执行第一次本地执行-Xmixed 混合模式 XX参数-XX:+PrintFlagsInitial 查看JVM的初始化参数-XX:+PrintFlagsFinal 查看JVM的运行参数 JVM参数有很多，只需要记住一些关键的即可。平时多积累知道有哪些参数就可以。忘记的话直接使用-help即可。也可以查看官网Java命令官网说明 也可以使用java -XX:+PrintFlagsFinal pid 对常用命令进行总结 常用命令jps [-ll]查看运行中的java进程，快速找到需要的java进程id-ll 查看详细的class名 jinfo查看java的信息 命令比较简单，主要查看某些命令的配置参数jinfo -flags [pid] 可查看一些基础命令 jstat 查看JVM的统计信息jstat -&lt;option&gt; [-t] [-h] [&lt;interval&gt; [&lt;count&gt;]] option：参数 -t：添加一个时间戳参数 -h：指定多少行输出一次表头 interval：执行每次的间隔时间，单位为毫秒 count： 用于指定输出多少次记录，缺省则会一直打印 option的参数有很多 -class 显示ClassLoad的相关信息； -compiler 显示JIT编译的相关信息； -gc 显示和gc相关的堆信息； -gccapacity 显示各个代的容量以及使用情况； -gcmetacapacity 显示metaspace的大小 -gcnew 显示新生代信息； -gcnewcapacity 显示新生代大小和使用情况； -gcold 显示老年代和永久代的信息； -gcoldcapacity 显示老年代的大小； -gcutil 显示垃圾收集信息； -gccause 显示垃圾回收的相关信息（通-gcutil）,同时显示最后一次或当前正在发生的垃圾回收的诱因； -printcompilation 输出JIT编译的方法信息； 重点说一下-gc 执行以上命令就可以查看gc相关的堆信息，我写的每秒刷新一次。一共10次 S0C、S2C、S0U、S1U：S0和S1的总量和使用量 EC、EU：Eden区的总量和使用量 OC、OU：Old区的总量和使用量 MC、MU：Metaspace区的总量和使用量 CCSC、CCSU：压缩类控件总量和使用量 YGC、YGCT：YoungGC的次数和时间 FGC、FGCT：FullGC的次数和时间 GCT：总的GC时间 也可以在项目中加入XX参数，当出现gc时，自动写入日志，注意日志的文件夹必须提前创建。 123456-XX:+PrintGC 输出GC日志-XX:+PrintGCDetails 输出GC的详细日志-XX:+PrintGCTimeStamps 输出GC的时间戳（以基准时间的形式）-XX:+PrintGCDateStamps 输出GC的时间戳（以日期的形式，如 2013-05-04T21:53:59.234+0800）-XX:+PrintHeapAtGC 在进行GC的前后打印出堆的信息-Xloggc:..&#x2F;logs&#x2F;gc.log 日志文件的输出路径 jmapjmap主要用于查看JVM内存信息。主要还可以到处dump文件。利用MAT来分析内存溢出 1jmap -dump:format=b,file=help.hprof 9480 也可以在项目中加入XX参数。在项目出现内存溢出时，自动导出dump。 12-XX:+HelpDumpOnOutOfMemoryError-XX:HelpDumpPath&#x3D;.&#x2F; jstackjstack 主要是用于打印线程，检查死锁和死循环jstack [pid] 如果程序中存在死锁和死循环。最后一行一般是可以看到的。 实际中可以使用 jstack [pid] &gt; aaa.txt 将其输出到文件中再仔细研究问题。也可以的 NEW 线程还没有启动 RUNNALE 准备启动 BLACKED 等待锁中获取，以执行 WAITING 等待中 TIMED WAITING 等待中 TERMINATED 退出 远程监控jvisualVM 监控java进程 远程监控时需要添加以下参数 12345-Dcom.sun.management.jmxremote-Dcom.sun.management.jmxremote.port&#x3D;9099-Dcom.sun.management.jmxremote.ssl&#x3D;false-Dcom.sun.management.jmxremote.authenticate&#x3D;false-Djava.rmi.server.hostname&#x3D;127.0.0.1","tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"Redis基础","date":"2019-03-12T01:58:51.000Z","path":"2019/03/12/nosql/Redis基础/","text":"Redis基础基础数据结构 REDIS_ENCODING_INT（long类型的整数） REDIS_ENCODING_EMBSTR embstr （编码的简单动态字符串） &lt; 44字节使用 REDIS_ENCODING_RAW （简单动态字符串） REDIS_ENCODING_HT （字典） REDIS_ENCODING_LINKEDLIST （双端链表） REDIS_ENCODING_ZIPLIST （压缩列表） REDIS_ENCODING_INTSET （整数集合） REDIS_ENCODING_SKIPLIST （跳跃表和字典） string： raw int embstr hash: hashTable zipList list: linkedList zipList set： hashTable intset zset: skiplist ziplist 各种类型的常用命令官网指令查询 连接远程连接时，redis配置文件，需要将bind修改为指定的ip才能连接 redis-cli -h 138.138.138.138 -p 6379 -a password 通用指令keys 不建议生产环境使用 O(n) keys * 查出所有keykeys test? 查出所有test开头的5位字符，?表示一个字符keys test* 查出test开头所有key 实际生产环节中可以使用。查询指定数量的keySCAN 0 MATCH scxx* COUNT 200 dbsize 查询所有数据总数 exists key 判断key是否存在return: 0 1 del key 删除某个key，可以一次性删除说个return: 0 成功删除key的数量 expire key seconds 设置过期时间 ttl key 查询key剩余的过期时间return: -1：没有过期时间 -2：key不存在 persist key 去掉过期时间 type key 判断key的类型return: string,hash,list,zet,szet,none stringget set del incr decr 自增减1 incrby decrby 自增减自定义数字 setnx key不存在才设置 setxx key存在才设置 mset mget 批量操作 append 添加字符串 return: 新的字符串长度 strlen 字符串长度 getrange key start end 获取指定的字符串，下标从0开始 setrange key offset value 修改指定下标后的所有字符串 hashhget hset hdel hset key filed value hgetall 获取的所有和filed和value hexists 判断某个filed是否存在 hlen 获取filed的数量 hmget hmset 批量操作 hsetnx 存在则新增数据 hincrby 增加自定义数字(没有自定义减) list： 有序，可以重复，左右两边弹出lpush rpush 左边插入，右边插入 key value1 value2 value3 value4 lpop rpop 左边弹出数据,右边弹出数据 linsert 在list指定的值前后插入newValue linsert key before|after value newValue lrem 删除数据 lrem key count value注意count的值的特性: count &gt; 0 : 从头到尾删除count个等于value的值 count &lt; 0 ：从尾到头删除count个等于value的值 count = 0 ：删除所有等于vlaue的值 ltrim 修剪数组，保留指定的部分ltrim key start end 注意负数，0：表示第一个数据 -1：表示倒数第一个数据 -2：表示倒数第二个数据… lrange key start end 范围查询 闭区间 lindex key index 根据下标取数据 llen key 获取列表的长度 lset key index newValue 设置指定下标的数据 blpop brpop 阻塞版本 set 集合 不可以重复sadd 添加元素，可添加多个元素 srem 删除数据,可删除多个元素 scard 获取集合的大小 sinter sdiff sunion 获取集合的交集、差集、并集 sismember 判断元素是否在集合中 srandmember 随机挑选指定数量的元素 spop 随机弹出一个元素 smembers 取出集合中的所有元素 zset 有序集合 , 有序，score可以重复,member不可以重复zadd 添加元素 zadd key score member score elment … zrem 删除指定的元素zrem key member … zcard 获取集合的大小 zscore key member 获取指定member的分数 zincrby key num member 增加某个member的分数 zrank key member 获取排名(从0开始) zrevrank key member 获取指定元素的排序(从高到低排序) zrange key strat end 获取排名内的数据 zrevrange 根据排名内的数据（从高到低） zrangebyscore 获取指定分数之间的数据zrangebyscore key minScore maxScore zrevrangebyscore 获取制定分数之间的数据，从高到低排名 zcount 获取指定分数范围的个数zcount key minScore maxScore zremrangebyrank 根据排名来删除数据zremrangebyrank key start end zremrangebyscore 删除指定分数内的数据zremrangebyscore key minScore maxScore zinterscore zunionscore 集合操作。 获取集交集，并集","tags":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/tags/Redis/"}]},{"title":"其他模式","date":"2019-02-14T01:58:51.000Z","path":"2019/02/14/javabase/shejimoshi/其他模式/","text":"其他模式前言设计模式概括的讲很多资料写的项目的有23种设计模式，但是实际上设计模式都比较简单。有些时候有些模式一直都在用，直到详细看了那么设计模式才了解原来这也算是一个设计模式，比如模板方法模式。有些设计模式也比较简单，有些则实际用的不多。我也没撒东西拿出来当读讲。所以这片文档做一个统称。 毕竟当我们深刻了解所有的设计模式后，可以发现这已经和代码没有任何关系了。一切都是看业务看需求。看我们是不是能够深刻的抓住业务的主体。抓住其中痛点以及编码的痛点。同时当别人想对我们的代码进行扩充时也能够在不修改源代码的情况下进行自主扩充。 毕竟我们要抓住其本质：开闭原则。对扩展开放，对修改闭合。 模板方法模式模板方法：通常我们在类中定义一个操作的骨干架子，将一些不确定的量交给子类去实现。子类可以通过扩展的方式来功能。 优点以及特点： 封装了不可变部分，将扩展部分交给子类去实现，父类中也可以提取公共代码，提高代码的复用率 符合开闭原则 缺点： 扩展部分交给子类实现会导致子类增多。系统比较臃肿 在查看代码逻辑时，是一种反向控制结构，提高代码的阅读难度（Spring常有…） 享元模式享元模式是将某些大量使用的都对象，由于具有相同性，所有可以对象进行提前缓存。达到共享元数据的概念（有点缓存的概率）。 比如Integer.valueOf(int i)中将-128~128之间的数据进行缓存，因为JVM任务这些小整数，使用频率比较高！ 比如String的常量池，也可以说是享元模式 装饰模式说到装饰模式首先想到的是IO，因为IO就是装饰者模式的一种使用。 装饰模式是在主对象的主体结构不变化的情况，对其进行扩充。使其更加好用。 比如IO中常用的：BufferedInputStream、BufferedReader都是对InputStream和Reader的装饰类","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"单例模式","date":"2019-02-13T01:58:51.000Z","path":"2019/02/13/javabase/shejimoshi/单例模式/","text":"单例模式前言单例模式算是设计模式中比较好理解，也比较重要的一种设计模式。单例模式属于创造型的设计模式。主要用于类的实例化。很多资料吧单例模式分为懒汉式，饿汉式.. 等等各种变化，这里可以已这为基础举一些简单的例子，好理解 单例模式主要我们可以分为三步 私有构造函数 初始化.可以提前初始化，可以在使用需要时初始化。 开放一个方法来获取唯一实例 优点： 一个类只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例 避免对共享资源的多重占用 缺点： 不适用于变化的对象，如果同一类型的对象总是要在不同的用例场景发生变化，单例就会引起数据的错误，不能保存彼此的状态。 由于单利模式中没有抽象层，因此单例类的扩展有很大的困难。 单例类的职责过重，在一定程度上违背了“单一职责原则”。 饿汉式什么叫饿汉式，其实就是提前加载。看代码 12345678910class A&#123; // 提前初始化 private final static A a = new A(); // 私有构造函数 private A()&#123;&#125; // 开放一个方法获取唯一实例 public static A getInstance()&#123; return a; &#125;&#125; 饿汉式是怎么做的？很简单，就是初始化的时候是提前初始化。这里初始化我只一个简单的new了一个A对象，实际中如果A对象比较重，可以写在静态代码块中。 这种写法是天然支持并发操作的。因为在类装载时便完成了初始化操作。实际就是在调用getInstance之前完成了A的初始化操作。所以getInstance实际已经没有了并发的危险 懒汉式什么叫懒汉式，其实就是懒加载。看代码 12345678910111213class A&#123; private static A a = null; // 私有构造函数 private A()&#123;&#125; // 开放一个接口获取实例 public static A getInstance()&#123; // 初始化 if(a == null)&#123; a = new A(); &#125; return a; &#125;&#125; 上面的代码，讲初始化的操作搬到了getInstance中了。在单线程中可以使用，但是如果涉及到并发，可能就不行了。因为很简单 a==null 这一步，在并发的时候，单线程1进入a==null，还没来得及初始化a。可能其他线程也进入a==null的判断。所以这不是线程安全的。 怎么改进？ 最简单的方法加锁 123456789class A&#123; private static A a = null; private A()&#123;&#125; // synchronized 加锁 public synchronized static A getInstance()&#123; if(a == null) a = new A(); return a; &#125;&#125; 这种synchronized加法比较简单，但是效率太差。比如100个线程要获取a，实际上a已经初始化好了。那么为什么还有100个线程去抢锁了？ 改进一下,缩小锁的颗粒度 1234567891011121314class A&#123; private static A a = null; private A()&#123;&#125; public static A getInstance()&#123; if(a == null)&#123; // 标识1 synchronized(A.class)&#123; a = new A(); &#125; &#125; return a; &#125;&#125; 这种锁的颗粒度是小了，但是问题在于标记1的位置，很可能一次性进入很多个线程，实际上导致刚开始每个线程拿到的都是不同的对象。 再改进一下 123456789101112131415class A&#123; private static A a = null; private A()&#123;&#125; public static A getInstance() &#123; if (a == null) &#123; synchronized (A.class) &#123; if(a == null)&#123; a = new A(); &#125; &#125; &#125; return a; &#125;&#125; 这就是我们常见的加锁时使用的双重检测，即可以保证性能，又可以保证稳定性，这中代码习惯很多地方都会使用。 但是其实上诉代码可不是完全可靠的。主要是因为指令重排序的问题。首先我们先了解一下a=new A()这句代码实际做了什么。 分配一块内存 M 在内存M上初始化A的数据 将M的内存地址给a 实际上a == null是针对第3步。但是由于指令重排序，在实际情况下，可以是123，可以是132 毕竟在单线程中都不影响。来讲一下实际情况。线程A调用getInstance方法，进入了a=new A()，然后按132的步骤初始化a，初始化到2的时候。线程B调用getInstance方法。发现a!=null（此时A虽然不等于null，但是a还没有初始化数据，直接使用可能出现异常）。直接返回了一个还没有初始化好的a对象。这样就会造成线程B拿到的a是有问题的。 怎么解决这个问题？ 通过添加volatile关键字来解决，volatile只要是保证a的可见性，同时也禁止指令重排序。所有123步骤是永远按123步骤走的。实际上volatile经常和双重检测一起使用。 123456789101112131415class A&#123; private static volatile A a = null; private A()&#123;&#125; public static A getInstance() &#123; if (a == null) &#123; synchronized (A.class) &#123; if(a == null)&#123; a = new A(); &#125; &#125; &#125; return a; &#125;&#125; 其他单例模式除了以上这些写法还可以通过内部类和枚举来使用，利用java的类加载来保证其安全性，也是推荐使用的 12345678910class A &#123; private A() &#123; &#125; // 子类B private static class B &#123; static A a = new A(); &#125; public static A getInstance() &#123; return B.a; &#125;&#125; 总结实际代码中用什么可以自己去考虑一下，比如有些类在项目中是肯定使用的，可以直接使用饿汉式，有些不确定使用性，可以考虑使用饿汉式，双重检测和内部类使用都可以。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"代理模式","date":"2019-02-12T01:58:51.000Z","path":"2019/02/12/javabase/shejimoshi/代理模式/","text":"代理模式前言代理类主要目的在于隔离目标类，可以在代理类写公用的代码比如日志，也可以加入一些缓存。也能起到降低耦合度的效果。有时候我们在不想修改目标的类的情况下修改逻辑。也在增加代理类。 代理类的使用主要分为2种方式：静态代理、动态代理 静态代理我们以买电脑为例子 123456789101112131415161718192021222324252627282930313233// 目标接口public interface IComputerStore &#123; String buyComputer();&#125;// 目标接口的具体实现类public class ComputerStore implements IComputerStore&#123; @Override public String buyComputer() &#123; return \"mac book\"; &#125;&#125;// 静态代理类public class ComputerStoreStaticProxy implements IComputerStore&#123; private IComputerStore computerStore; public ComputerStoreStaticProxy(IComputerStore computerStore) &#123; this.computerStore = computerStore; &#125; @Override public String buyComputer() &#123; System.out.println(\"收钱\"); String computer = computerStore.buyComputer(); System.out.println(\"发货\"); return computer; &#125;&#125;// testpublic class Main &#123; public static void main(String[] args) &#123; IComputerStore computerStore = new ComputerStore(); IComputerStore computerStoreStaticProxy = new ComputerStoreStaticProxy(computerStore); computerStoreStaticProxy.buyComputer(); &#125;&#125; 以上就是一个非常简单的静态代理模式，代码比较简单自己看吧。 这个写法缺点也比较明显，代理都是手工编写。不利于管理，而且如果类比较多，工作量大也比较大 动态代理JDK动态代理1234567891011121314151617181920212223// 编写动态代理public class JdkProxyHandler implements InvocationHandler &#123; private Object object; public JdkProxyHandler(Object object) &#123; this.object = object; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(\"收钱\"); Object result = method.invoke(object, args); System.out.println(\"拿到电脑\"); System.out.println(\"发货\"); return result; &#125;&#125;// JDK动态代理的调用public static void main(String[] args) throws Exception &#123; IComputerStore computerStore = new ComputerStore(); IComputerStore proxy = (IComputerStore)Proxy.newProxyInstance(ComputerStore.class.getClassLoader(), ComputerStore.class.getInterfaces(), new JdkProxyHandler(computerStore)); proxy.buyComputer();&#125; JDK生成的代理类都是继承Proxy且生成的代理类和委托类实现同一个接口，而且实现了InvocationHandler。通过调用invoke方法。来实现目标类的访问。 jdk动态代理只能代理接口 cglib代理123456789101112131415161718192021222324252627282930// 编写动态代理public class CglibProxyHandle implements MethodInterceptor &#123; private Object obj; public Object getInstance(Object obj) &#123; this.obj = obj; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(this.obj.getClass()); // 设置回调方法 enhancer.setCallback(this); // 创建代理对象 return enhancer.create(); &#125; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println(\"收钱\"); Object res = methodProxy.invokeSuper(o, objects); System.out.println(\"拿到电脑\"); System.out.println(\"发货\"); return res; &#125;&#125;// cglib代理的调用public static void main(String[] args) throws Exception &#123; CglibProxyHandle cglibProxyHandle = new CglibProxyHandle(); IComputerStore instance = (IComputerStore)cglibProxyHandle.getInstance(new ComputerStore()); instance.buyComputer();&#125; 注意cdlib生成的代理类是继承目标类的，实现接口Factory。所以可以代理普通类，但是方法不能是final，因为final 不能重写。fastClass机制所以执行效率要比jdk快，jdk通过反射机制来调用目标类 比较对三种代理进行一个简单的比较过程 代理 实现方式 优点 缺点 特点 静态代理 代理类和委托类实现一个接口，硬编码 简单，容易懂 硬编码不好管理，代码量大 - JDK动态代理 代理和委托类实现同一个接口，通过实现InvocationHandler重写invoke来实现访问委托类 复用度高，JDK自带 只能代理委托类实现的接口 底层通过反射机制来调用目标方法 cglib动态代理 代理通过将委托类作为父类。同时为其委托方法创建两个方法，一个是与委托方法签名相同的方法，它在方法中会通过super调用委托方法；另一个是代理类独有的方法。在代理方法中，它会判断是否存在实现了MethodInterceptor接口的对象，若存在则将调用intercept方法对委托方法进行代理 可以在运行时对类或者是接口进行增强操作，且委托类无需实现接口 不能对final类和final方法进行代理 底层将方法全部存入一个数组中，通过数组索引直接进行方法调用，调用效率比JDK高 本篇文章主要是结论性的东西，便于自己学习","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Git基本指令","date":"2019-01-12T01:58:51.000Z","path":"2019/01/12/otherDoc/git基本指令/","text":"git基本指令设置和查看全局配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546git config --global user.email &quot;your email&quot;git config --global user.name &quot;your name&quot;git config --global user.password &quot;your password&quot;git config user.name 查看用户名git config core.ignorecase false 设置忽略大小写为falsegit config --global core.quotepath false 设置支持中文git config --global core.autocrlf false 忽略自动处理回车换行git默认会根据你使用的平台来处理回车换行比如如果你在window开发，那么在你提交代码的时候，会自动把换行符改成回车换行。在你pull代码，也会自动把代码中的换行符变成回车换行符 如果你是mac os或者linux系统也是同理。他会自动处理。 正常情况下其实我任务无需修改。除非你能够确定你的项目没有杂用的情况。某个两个开发人员的代码看着会不一样。# 设置ss 当然这里 可以只对github使用代理git config --global http.proxy &#39;socks5:&#x2F;&#x2F;127.0.0.1:1086&#39;git config --global https.proxy &#39;socks5:&#x2F;&#x2F;127.0.0.1:1086&#39;git config --global http.https:&#x2F;&#x2F;github.com.proxy socks5:&#x2F;&#x2F;127.0.0.1:1086git config --global https.https:&#x2F;&#x2F;github.com.proxy socks5:&#x2F;&#x2F;127.0.0.1:1086# 设置代理git config --global https.proxy http:&#x2F;&#x2F;127.0.0.1:1080git config --global https.proxy https:&#x2F;&#x2F;127.0.0.1:1080# 取消代理git config --global --unset http.proxygit config --global --unset https.proxy&#x2F;&#x2F;查看仓库级的 configgit config –-local -l&#x2F;&#x2F;查看全局级的 configgit config –-global -l&#x2F;&#x2F;查看系统级的 configgit config –-system -l&#x2F;&#x2F;查看当前生效的配置git config -l git clone1git clone [github地址] 从远程仓库克隆一个版本库到本地 12345678# 默认在当前目录下创建和版本库名相同的文件夹并下载版本到该文件夹下git clone &lt;远程仓库的网址&gt;# 指定本地仓库的目录git clone &lt;远程仓库的网址&gt; &lt;本地目录&gt;# -b 指定要克隆的分支，默认是master分支git clone &lt;远程仓库的网址&gt; -b &lt;分支名称&gt; &lt;本地目录&gt; git init将文件夹加入git管理。文件夹会生成一个.git目录 git status查看本地仓库的状态。 git status -s可查看简化的git目录 git add将文件添加到寄存区 12345678910# 把指定的文件添加到暂存区中git add &lt;文件路径&gt;# 添加所有修改、已删除的文件到暂存区中git add -u [&lt;文件路径&gt;]git add -a [&lt;文件路径&gt;] 对新增目录也处理# 查看所有修改、已删除但没有提交的文件，进入一个子命令系统git add -i [&lt;文件路径&gt;]git add --interactive [&lt;文件路径&gt;] git commit将暂存区中的文件提交到本地仓库中 123456789# 把暂存区中的文件提交到本地仓库中并添加描述信息git commit -m &quot;&lt;提交的描述信息&gt;&quot;# 把所有修改、已删除的文件提交到本地仓库中# 不包括未被版本库跟踪的文件，等同于先调用了 &quot;git add -u&quot;git commit -a -m &quot;&lt;提交的描述信息&gt;&quot;# 修改上次提交的描述信息git commit --amend git remote 操作远程库123456789101112131415161718# 列出已经存在的远程仓库git remote# 列出远程仓库的详细信息，在别名后面列出URL地址git remote -vgit remote --verbose# 添加远程仓库git remote add &lt;远程仓库的别名&gt; &lt;远程仓库的URL地址&gt;# 修改远程仓库的别名git remote rename &lt;原远程仓库的别名&gt; &lt;新的别名&gt;# 删除指定名称的远程仓库git remote remove &lt;远程仓库的别名&gt;# 修改远程仓库的 URL 地址git remote set-url &lt;远程仓库的别名&gt; &lt;新的远程仓库URL地址&gt; git branch 操作 Git 的分支命令1234567891011121314151617181920# 列出本地的所有分支，当前所在分支以 &quot;*&quot; 标出git branch# 列出本地的所有分支并显示最后一次提交，当前所在分支以 &quot;*&quot; 标出git branch -v# 创建新分支，新的分支基于上一次提交建立git branch &lt;分支名&gt;# 修改分支名称# 如果不指定原分支名称则为当前所在分支git branch -m [&lt;原分支名称&gt;] &lt;新的分支名称&gt;# 强制修改分支名称git branch -M [&lt;原分支名称&gt;] &lt;新的分支名称&gt;# 删除指定的本地分支git branch -d &lt;分支名称&gt;# 强制删除指定的本地分支git branch -D &lt;分支名称&gt; git checkout 检出命令，用于创建、切换分支等123456789101112# 切换到已存在的指定分支git checkout &lt;分支名称&gt;# 创建并切换到指定的分支，保留所有的提交记录# 等同于 &quot;git branch&quot; 和 &quot;git checkout&quot; 两个命令合并git checkout -b &lt;分支名称&gt;# 创建并切换到指定的分支，删除所有的提交记录git checkout --orphan &lt;分支名称&gt;# 替换掉本地的改动，新增的文件和已经添加到暂存区的内容不受影响git checkout &lt;文件路径&gt; git cherry-pick12# 把已经提交的记录合并到当前分支git cherry-pick &lt;commit ID&gt; git fetch 从远程仓库获取最新的版本到本地的 tmp 分支上12345# 将远程仓库所有分支的最新版本全部取回到本地git fetch &lt;远程仓库的别名&gt;# 将远程仓库指定分支的最新版本取回到本地git fetch &lt;远程主机名&gt; &lt;分支名&gt; git merge 合并分支12# 把指定的分支合并到当前所在的分支下git merge &lt;分支名称&gt; git diff 比较版本之间的差异123456789101112131415161718# 比较当前文件和暂存区中文件的差异，显示没有暂存起来的更改git diff# 比较暂存区中的文件和上次提交时的差异git diff --cachedgit diff --staged# 比较当前文件和上次提交时的差异git diff HEAD# 查看从指定的版本之后改动的内容git diff &lt;commit ID&gt;# 比较两个分支之间的差异git diff &lt;分支名称&gt; &lt;分支名称&gt;# 查看两个分支分开后各自的改动内容git diff &lt;分支名称&gt;...&lt;分支名称&gt; git pull从远程仓库获取最新版本并合并到本地。首先会执行 git fetch，然后执行 git merge，把获取的分支的 HEAD 合并到当前分支。 git push把本地仓库的提交推送到远程仓库 12345678# 把本地仓库的分支推送到远程仓库的指定分支git push &lt;远程仓库的别名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt;git push -u origin master # -u 会设置默认push数据# 删除指定的远程仓库的分支git push &lt;远程仓库的别名&gt; :&lt;远程分支名&gt;git push &lt;远程仓库的别名&gt; --delete &lt;远程分支名&gt; git log 显示提交的记录12345678# 打印所有的提交记录git log# 打印从第一次提交到指定的提交的记录git log &lt;commit ID&gt;# 打印指定数量的最新提交的记录git log -&lt;指定的数量&gt; git reset 还原提交记录12345678910111213141516# 重置暂存区，但文件不受影响# 相当于将用 &quot;git add&quot; 命令更新到暂存区的内容撤出暂存区，可以指定文件# 没有指定 commit ID 则默认为当前 HEADgit reset [&lt;文件路径&gt;]git reset --mixed [&lt;文件路径&gt;]# 将 HEAD 的指向改变，撤销到指定的提交记录，文件未修改git reset &lt;commit ID&gt;git reset --mixed &lt;commit ID&gt;# 将 HEAD 的指向改变，撤销到指定的提交记录，文件未修改# 相当于调用 &quot;git reset --mixed&quot; 命令后又做了一次 &quot;git add&quot;git reset --soft &lt;commit ID&gt;# 将 HEAD 的指向改变，撤销到指定的提交记录，文件也修改了git reset --hard &lt;commit ID&gt; git revert生成一个新的提交来撤销某次提交，此次提交之前的所有提交都会被保留 12# 生成一个新的提交来撤销某次提交git revert &lt;commit ID&gt; git tag操作标签的命令 1234567891011121314151617181920212223# 打印所有的标签git tag# 添加轻量标签，指向提交对象的引用，可以指定之前的提交记录git tag &lt;标签名称&gt; [&lt;commit ID&gt;]# 添加带有描述信息的附注标签，可以指定之前的提交记录git tag -a &lt;标签名称&gt; -m &lt;标签描述信息&gt; [&lt;commit ID&gt;]# 切换到指定的标签git checkout &lt;标签名称&gt;# 查看标签的信息git show &lt;标签名称&gt;# 删除指定的标签git tag -d &lt;标签名称&gt;# 将指定的标签提交到远程仓库git push &lt;远程仓库的别名&gt; &lt;标签名称&gt;# 将本地所有的标签全部提交到远程仓库git push &lt;远程仓库的别名&gt; –tags git mv重命名文件或者文件夹 12# 重命名指定的文件或者文件夹git mv &lt;源文件&#x2F;文件夹&gt; &lt;目标文件&#x2F;文件夹&gt; git rm删除文件或者文件夹 12345678# 移除跟踪指定的文件，并从本地仓库的文件夹中删除git rm &lt;文件路径&gt;# 移除跟踪指定的文件夹，并从本地仓库的文件夹中删除git rm -r &lt;文件夹路径&gt;# 移除跟踪指定的文件，在本地仓库的文件夹中保留该文件git rm --cached 实际操作场景1. 删除掉本地不存在的远程分支多人合作开发时，如果远程的分支被其他开发删除掉，在本地执行 git branch –all 依然会显示该远程分支，可使用下列的命令进行删除： 123456# 使用 pull 命令，添加 -p 参数git pull -p# 等同于下面的命令git fetch -pgit fetch --prune origin 参考地址 可在此查看所有命令 官网 2. 将两个独立的git合并有一次我将本地的.git 删了之后。 在使用remote建立关联只会。 push会提示要我先pull。然而pull时会报错！ 1234git pull origin masterFrom https:&#x2F;&#x2F;github.com&#x2F;dute7liang&#x2F;document * branch master -&gt; FETCH_HEADfatal: refusing to merge unrelated histories 表示两个是独立的git。处理方式可以添加--allow-unrelated-histories即可git pull origin master --allow-unrelated-histories执行以下命令即可正常操作！ 推荐阅读猴子都能懂的GIT入门","tags":[{"name":"Git","slug":"Git","permalink":"http://yoursite.com/tags/Git/"}]},{"title":"观察者模式","date":"2019-01-12T01:58:51.000Z","path":"2019/01/12/javabase/shejimoshi/观察者模式/","text":"观察者模式前言观察者模式是一个非常重要的模式，虽然在实际工作中可能很少去直接自己去构造一个观察者模式，并不像单例模式、工厂模式、模板方法模式这样。直接硬编码写出来。但是我们肯定会用到它的补充形式的。比如发布-订阅、监听器、Spring的事件驱动模式。因为毕竟观察者模式直接使用有时候不能达到我们的解耦要求。所以才有了上面的这些常用的东西。 为什么使用观察者模式在软件系统中，当一个对象行为依赖另外一个对象的状态时。如果不是使用观察者模式的通用结构。则只能在另一个线程中不停的监听查看对象所需要的依赖。在一个复杂的系统中，可能会开启很多线程来实现这一功能，会严重浪费系统的性能。观察者模式的意义也在于此，它可以在单线程中，使某一对象，及时得知自身所依赖的状态的变化，根据其变化做出来相应的动作。 简单的观察者模式观察者模式主要分为四个角色 角 色 作 用 主题接口 指被观察者对象。当其状态发生改变，它会将这个变化通知给观察者，它维护了观察者所需要依赖的状态 具体主题 具体主题实现了主题接口 观察者接口 观察者接口定义了观察者的基本方法。当依赖状态发生改变时，主题接口就会调用观察者模式的方法 具体观察者 具体观察者实现了观察者接口 我们来看一下代码的基本实现 1234567891011121314151617181920212223242526272829303132// 观察者接口public interface IObserver&#123; void update(Event event);&#125;// 主题接口public interface ISubject &#123; void addObserver(IObserver server); // 新增观察者 void delObserver(IObserver server); // 删除观察者 void inform(); // 通知观察者&#125;// 主题接口实现public class SubjectImpl implements ISubject&#123; Vector&lt;IObserver&gt; observers = new Vector&lt;&gt;(); public void addObserver(IObserver server)&#123; observers.add(server); &#125; public void delObserver(IObserver server)&#123; observers.removeElement(server); &#125; public void inform()&#123; Event event = new Event(); for(IObserver server : observers)&#123; server.update(evt); &#125; &#125;&#125;// 具体观察者public class ObserverImpl implements IObserver&#123; public void update(Event event)&#123; log.info(\"接受到消息！\"); &#125;&#125; 上面这段代码就是一个简单的实现。可以看出来。其实不复杂。就是简单的状态在需要通知的时候主题接口调用一下通知接口即可。 JDK中的观察者模式JDK已经为我们准备了一套现有的观察者模式的实现，我们可以直接使用它即可，在java.util包中，包括Observable和Observer接口 在看一些代码的实现,这里我们以书本订阅的模式 1234567891011121314151617181920212223242526// 订阅书的人@Slf4jpublic class PaperListener implements Observer &#123; @Override public void update(Observable o, Object arg) &#123; log.info(\"收到书了：&#123;&#125;\",arg); &#125;&#125;public class Bookstore extends Observable &#123; public static void main(String[] args) throws InterruptedException &#123; PaperListener paperListener1 = new PaperListener(); PaperListener paperListener2 = new PaperListener(); Bookstore bookstore = new Bookstore(); bookstore.addObserver(paperListener1); // 订阅人1 bookstore.addObserver(paperListener2); // 订阅人2 Thread.sleep(1000); // 杂志到了 bookstore.setChanged(); bookstore.notifyObservers(\"西游记\"); bookstore.setChanged(); bookstore.notifyObservers(\"三国演义\"); &#125;&#125; 执行结果 123421:02:44.360 [main] INFO com.document.observer.PaperListener - 收到书了：西游记21:02:44.384 [main] INFO com.document.observer.PaperListener - 收到书了：西游记21:02:44.384 [main] INFO com.document.observer.PaperListener - 收到书了：三国演义21:02:44.385 [main] INFO com.document.observer.PaperListener - 收到书了：三国演义 其实当我们查看Observable的源码，也就知道了其实里面和简单的观察者模式是类似的。不过它为了公用性和并发性做了一些改造。我们每次都要去改变一个change变量才能去通知。实际使用中也要继承Observable来做的。有兴趣的可以去自己使用下 不过看起来还有缺点，比如它是需要继承Class来实现。而Java只能继承一个类。而且它的标记change只有一个。不能做到组合标记 发布-订阅和观察者模式前面说了发布订阅可以说是观察者模式的一个补充，因为观察者模式的主题和订阅至于两层，里面的订阅者的维护工作是交给主题自己本身来做的，耦合度不太好。所有发布订阅相当于把他拆分成三个成员：主题、订阅者、维护队列者。这样主题和订阅者就做到完全解耦的工作。队列的维护交给一个实际的类或者服务来做。 所有发布-订阅模式比观察者模式有更好的耦合度，但是在设计思想上是统一的 当然如果你把这个模式在扩展下，比如把维护队列的对象扩展成一个服务，那么就是一个简单的消息队列的原型 Spring中的事件驱动模式这里讲一下Spring中的ApplicationListener，因为它也是观察者模式的一个实现(毕竟挖了坑，要填)。 先看下简单的使用代码 1234567891011121314151617181920212223// 事件public class MyEvent extends ApplicationEvent &#123; public MyEvent(Object source) &#123; super(source); &#125;&#125;// 监听器 注意要加入Bean，Spring会在启动中，将其加入发布广播器中@Slf4j@Componentpublic class MyListener implements ApplicationListener&lt;MyEvent&gt; &#123; @Override public void onApplicationEvent(MyEvent event) &#123; log.info(\"收到消息了:&#123;&#125;\",event); &#125;&#125;// 开始发布消息@SpringBootApplicationpublic class WebBaseApplication &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext run = SpringApplication.run(WebBaseApplication.class, args); run.publishEvent(new MyEvent(new Object())); &#125;&#125; 输出日志：收到消息了:com.duteliang.webbase.listener.MyEvent[source=java.lang.Object@3d4e405e] 其实也是和观察者模式的设计思想是类似的。但是做了一些变化。看下发布的源码 123456789101112131415161718192021222324252627282930protected void publishEvent(Object event, @Nullable ResolvableType eventType) &#123; Assert.notNull(event, \"Event must not be null\"); // Decorate event as an ApplicationEvent if necessary ApplicationEvent applicationEvent; if (event instanceof ApplicationEvent) &#123; applicationEvent = (ApplicationEvent) event; &#125; else &#123; applicationEvent = new PayloadApplicationEvent&lt;&gt;(this, event); if (eventType == null) &#123; eventType = ((PayloadApplicationEvent&lt;?&gt;) applicationEvent).getResolvableType(); &#125; &#125; // Multicast right now if possible - or lazily once the multicaster is initialized if (this.earlyApplicationEvents != null) &#123; this.earlyApplicationEvents.add(applicationEvent); &#125; else &#123; // 这里关键代码，获取广播器，发布消息 getApplicationEventMulticaster().multicastEvent(applicationEvent, eventType); &#125; // Publish event via parent context as well... if (this.parent != null) &#123; if (this.parent instanceof AbstractApplicationContext) &#123; ((AbstractApplicationContext) this.parent).publishEvent(event, eventType); &#125; else &#123; this.parent.publishEvent(event); &#125; &#125;&#125; 跟下去看下广播器代码 12345678910111213141516171819202122232425// 默认使用的SimpleApplicationEventMulticaster广播器class SimpleApplicationEventMulticaster implements ApplicationEventMulticaster&#123; @Override public void multicastEvent(final ApplicationEvent event, @Nullable ResolvableType eventType) &#123; ResolvableType type = (eventType != null ? eventType : resolveDefaultEventType(event)); Executor executor = getTaskExecutor(); for (ApplicationListener&lt;?&gt; listener : getApplicationListeners(event, type)) &#123; if (executor != null) &#123; // 如果有Executor 走异步调用 executor.execute(() -&gt; invokeListener(listener, event)); &#125; else &#123; // 同步 invokeListener(listener, event); &#125; &#125; &#125; // invokeListener 实际是调用这个 doInvokeListener方法，我省略了一个 private void doInvokeListener(ApplicationListener listener, ApplicationEvent event) &#123; try &#123; listener.onApplicationEvent(event); &#125; catch (ClassCastException ex) &#123; // 无关代码忽略 &#125; &#125;&#125; 看到这里其实广播器SimpleApplicationEventMulticaster就相等于主题实现。从接口ApplicationEventMulticaster就可以看到有管理观察者的方法。ApplicationListener相当于观察者接口。 Spring引进了Event的概念，使其功能更加丰富了而已，调用观察者的时候根据事件类型来通知。 也可以选择异步通知还是同步通知，以及是否忽略错误等功能。 比如@EventListener就是为此而建立的，可以异步监听消息。更多的功能可以自己去查下资料了！ 1234567@Componentpublic class OrderEventListener &#123; @EventListener public void handleOrderEvent(OrderEvent event) &#123; System.out.println(\"我监听到了handleOrderEvent发布的message为:\" + event.getMsg()); &#125;&#125; 在开发中如果有需要使用观察者模式，可以推荐Guava 中的EventBus，对其的扩展非常丰富。可以去尝试一下","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"linux常用命令","date":"2018-07-12T01:58:51.000Z","path":"2018/07/12/otherDoc/linux常用命令/","text":"linux常用命令文件文件权限当使用ll时，我们经常可以看到左边有一串数据。即为改文件的权限 123456-rwxrwxrwx 1 smb root 366673794 11月 11 19:57 file.hprof-rwxr-xr-x 1 smb root 1021 11月 8 09:06 aa.sh-rwxr-xr-x 1 smb root 279 11月 8 09:02 bbb.sh-rw-r--r-- 1 root root 0 11月 16 13:55 testdrwxr-xr-x 3 smb root 22 11月 16 10:04 write-storage-filedrwxr-xr-x 8 smb root 195 11月 15 19:41 sss 权限 文件 其他数字，说明为文件夹，数字为文件夹内的文件数 文件拥有者 所属的组 文件大小，单位是byte 创建时间 文件名 第一栏即为权限的意思，一共10位字符 主要分为四部分。1 3 3 3分别的含义为【文件或文件夹】【owner权限】【group权限】【others权限】【文件是-，文件夹是d】【r/w/x相加】【r/w/x相加】【r/w/x相加】 需要理解的就是read,write,executor, 也就是你对于此文件属于哪个部分，同时对于哪个部分的权限即可。 同时还可以用数字表示：r ——– 4w ——– 2e ——– 1 这样修改权限就可以直接使用数字来修改。 chmod 比如常用的chmod 777 [file or dir]可以将文件的权限全放开！ 文件操作ls (选项) (目录) 查看文件-l 查看所有详细文件-a 显示所有文件 cd 切换目录pwd 显示当前文件目录mkdir (选项)(参数) 创建文件夹-p 若父文件夹不存在，会自动创建父文件夹 touch 主要用于创建空文件或者修改文件时间-a 修改文件的Access时间，访问时间-m 修改文件的Modify时间，修改时间-c 修改文件的change时间，目录或者权限变更时间 stat 可以查看文件时间记录 rm 删除文件，一个or多个-f 忽略提示，直接删除-r/-R 递归删除 cp 复制文件-R 递归操作，注意cp默认不支持复制目录，复制目录需要加上-R-f 强制处理，不进行提示-a 复制的文件与源文件时间一样 mv 移动-f 强制处理，不进行提示 将目录/usr/men/所有文件移动到当前目录下mv /usr/men/* . 解压文件tar -zxvf fileName 解压tar文件unzip fileName 解压zip文件(需要安装脚本) 123456789*.tar 用 tar -xvf 解压*.gz 用 gzip -d或者gunzip 解压*.tar.gz和*.tgz 用 tar -zxvf 解压*.bz2 用 bzip2 -d或者用bunzip2 解压*.tar.bz2用tar -xjf 解压*.Z 用 uncompress 解压*.tar.Z 用tar -xZf 解压*.rar 用 unrar e解压*.zip 用 unzip 解压 查询文件findfind pathname -options [-print -exec -ok …] pathname: find命令所查找的目录路径。例如用.来表示当前目录，用/来表示系统根目录。 -name 按照文件名查找文件-iname 文件名称搜索，忽略大小写-type 查找某一类型的文件，比如f 表示普通文件 d 表示文件路径 locatelocate –basename ‘\\ssh’ 系统中搜索ssh文件夹 文件显示cat 显示文件内容适合小文件 -n 可显示文件行数 more 显示文件内容分屏显示文件内容 -&lt;数字&gt; 知道每屏显示的行数-d 显示一些提示-c 不进行滚屏操作，每次刷新这个屏幕 查看文件时，可利用一些按键来调整显示 Space : 显示下一屏内容 Enier : 显示下一行内容 Q : 退出 less 显示文件内容less和more 功能类似，但是比more要更好用，可以更好的搜索和查找文件内容，以及翻页。 参数 -N 显示行号-m 类似于more的显示百分比 交互模式的快捷键 空格/PgUp/Ctrl+d ： 向下翻页 PgDn/Ctrl+b : 向上翻页 回车 : 向下移动一行 y : 向上移动一行 G : 移动到最后一行 g : 移动到第一行 /字符串 : 向下搜索字符串 ?字符串 : 向上搜索字符串 n : 重复前一个搜索 N : 反向重复前一步搜索 Q : 退出 tail 查看文件（倒查）显示指定行数的文件，用于倒查 123tail file （显示文件file的最后10行）tail +20 file （显示文件file的内容，从第20行至文件末尾）tail -c 10 file （显示文件file的最后10个字符） head 查看文件（正查）显示指定行数的文件，用于正查和tail一样 vim 系统参数获取系统参数ps 查询进程-a 显示所有终端机下执行的程序，除了阶段作业领导者之外。-e/-A 显示所有进程-f 显示进程的信息 可利用grep来s搜索指定的进程ps -ef|grep &#39;java&#39; 查看电脑信息cat /proc/cpuinfo 来查看CPU信息 cat /proc/meminfo查看linux系统内存大小的详细信息 df -h查看linux系统各分区的使用情况 free 查看linux系统内存使用量和交换区使用量（-m 用M单位显示） 查看ip地址: ifconfig -a，ip addr show 防火墙12345678## 查看firewalld防火墙systemctl status firewalld# 开启service firewalld start# 重启service firewalld restart# 关闭service firewalld stop 其他nohup &amp;nohup主要用来不挂断的运行程序。正在启动运行程序时，程序时运行在终端中，如果终端关闭程序也会关闭。&amp; 是表示后台运行。 如果没有&amp; 则表示前端运行，此时我们做不了其他事了所以一般会两者一起使用 nohup command [arg...] [&amp;] nohup ./start.sh &gt;/dev/null 2&gt;&amp;1 &amp;一般情况我们这样写，后台启动程序，同时不输出nohup日志。 添加开机启动脚本123456# zookeeper为我新建的脚本文件chmod +x zookeeper# 将zookeeper整个脚本添加到开机启动项chkconfig --add zookeeper# 可查看开机启动项chkconfig --list 记录sed -i ‘s/\\r$//‘ xxxxxxx.sh 将文件中的\\r替换成空格","tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"}]},{"title":"Java解压缩zip","date":"2017-04-12T01:58:51.000Z","path":"2017/04/12/coding/java解压缩zip/","text":"Java解压缩zip前言java解压缩工具类，主流有两种方式。 java自带，不只是中文 Apache提供的ant jar，支持中文 其实两者的api的使用形式基本是一样的。这里直接贴出两个代码。也可以在github中查看 Java原生的123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165package com.document.zip;import lombok.extern.slf4j.Slf4j;import java.io.*;import java.nio.charset.Charset;import java.util.Enumeration;import java.util.zip.ZipEntry;import java.util.zip.ZipFile;import java.util.zip.ZipOutputStream;/** * 利用java原生的类，来实现zip的解压缩工具类 * 需要注意的是java原生的不支持中文名 * @author: zl * @Date: 2019/12/8 16:28 */@Slf4jpublic class ZipUtil &#123; /** * 缓冲大小 */ private static int BUFFER_SIZE = 2 &lt;&lt; 10; /** * 是否保留原来的目录结构 * true: 保留目录结构; * false: 所有文件跑到压缩包根目录下(注意：不保留目录结构可能会出现同名文件,会压缩失败) */ private static final boolean KeepDirStructure = true; /** * 压缩文件 * @param srcDir 源文件路径 * @param outPathFile 输出路径(带文件名) * @param isDelSrcFile 解压后 是否删除源路径文件 * @throws RuntimeException */ public static void toZip(String srcDir, String outPathFile, boolean isDelSrcFile) &#123; long start = System.currentTimeMillis(); File sourceFile = new File(srcDir); if(!sourceFile.exists())&#123; throw new RuntimeException(\"需压缩文件或者文件夹不存在\"); &#125; FileOutputStream out = null; ZipOutputStream zos = null; try &#123; out = new FileOutputStream(new File(outPathFile)); zos = new ZipOutputStream(out); compress(sourceFile, zos, sourceFile.getName()); if(isDelSrcFile)&#123; sourceFile.delete(); &#125; log.info(\"原文件:&#123;&#125;. 压缩到:&#123;&#125;完成. 是否删除原文件:&#123;&#125;. 耗时:&#123;&#125;ms. \",srcDir,outPathFile,isDelSrcFile, System.currentTimeMillis()-start); &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125; finally &#123; try &#123; if (zos != null) zos.close(); if (out != null) out.close(); &#125; catch (Exception e) &#123;&#125; &#125; &#125; /** * 递归压缩方法 * @param sourceFile 源文件 * @param zos zip输出流 * @param name 压缩后的名称 */ private static void compress(File sourceFile, ZipOutputStream zos, String name) throws IOException &#123; byte[] buf = new byte[BUFFER_SIZE]; if (sourceFile.isFile()) &#123; zos.putNextEntry(new ZipEntry(name)); int len; FileInputStream in = new FileInputStream(sourceFile); while ((len = in.read(buf)) != -1) &#123; zos.write(buf, 0, len); &#125; zos.closeEntry(); in.close(); &#125; else &#123; File[] listFiles = sourceFile.listFiles(); if (listFiles == null || listFiles.length == 0) &#123; if (KeepDirStructure) &#123; zos.putNextEntry(new ZipEntry(name + \"/\")); zos.closeEntry(); &#125; &#125; else &#123; for (File file : listFiles) &#123; if (KeepDirStructure) &#123; compress(file, zos, name + \"/\" + file.getName()); &#125; else &#123; compress(file, zos, file.getName()); &#125; &#125; &#125; &#125; &#125; /** * zip解压 * @param srcFile zip源文件 * @param destDirPath 解压后的目标文件夹 * @throws RuntimeException 解压失败会抛出运行时异常,也可以自定义异常 */ public static void unZip(File srcFile, String destDirPath) &#123; long start = System.currentTimeMillis(); // 判断源文件是否存在 if (!srcFile.exists()) &#123; throw new RuntimeException(\"zip源文件不存在！\"); &#125; File descFile = new File(destDirPath); if(!descFile.exists()) descFile.mkdirs(); // 开始解压 ZipFile zipFile = null; InputStream is = null; FileOutputStream fos = null; try &#123; zipFile = new ZipFile(srcFile, Charset.forName(\"GBK\")); Enumeration&lt;? extends ZipEntry&gt; entries = zipFile.entries(); while (entries.hasMoreElements()) &#123; ZipEntry entry = entries.nextElement(); log.info(\"解压 &#123;&#125;\",entry.getName()); if (entry.isDirectory()) &#123; // 目录 String dirPath = destDirPath + \"/\" + entry.getName(); File dir = new File(dirPath); dir.mkdirs(); &#125; else &#123; // 文件 File targetFile = new File(destDirPath + \"/\" + entry.getName()); if(!targetFile.getParentFile().exists())&#123; targetFile.getParentFile().mkdirs(); &#125; targetFile.createNewFile(); // 将压缩文件内容写入到这个文件中 is = zipFile.getInputStream(entry); fos = new FileOutputStream(targetFile); int len; byte[] buf = new byte[BUFFER_SIZE]; while ((len = is.read(buf)) != -1) &#123; fos.write(buf, 0, len); &#125; // 关流顺序，先打开的后关闭 fos.close(); is.close(); &#125; &#125; long end = System.currentTimeMillis(); log.info(\"解压完成，耗时：&#123;&#125; ms\",end - start); &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125; finally &#123; try &#123; if(fos != null) fos.close(); if(is != null) is.close(); if(zipFile != null) zipFile.close(); &#125; catch (IOException e) &#123; // do nothing &#125; &#125; &#125;&#125; Apache ant jar这里使用的jar包为1.9.7，其他版本没有测试过 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.ant&lt;/groupId&gt; &lt;artifactId&gt;ant&lt;/artifactId&gt; &lt;version&gt;1.9.7&lt;/version&gt;&lt;/dependency&gt; 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184package com.document.zip;import lombok.extern.slf4j.Slf4j;import org.apache.tools.zip.ZipEntry;import org.apache.tools.zip.ZipFile;import org.apache.tools.zip.ZipOutputStream;import java.io.*;import java.util.Enumeration;import java.util.List;/** * 利用Apache Ant的jar包来解压缩zip工具类。 * 相对于java原生的技术，可以支持中文 * @author: zl * @Date: 2019/12/8 16:29 */@Slf4jpublic class AntZipUtil &#123; /** * 缓冲大小 */ private static int BUFFER_SIZE = 2 &lt;&lt; 10; public static void toZip(String srcDir, String zipPath, boolean isDelSrcFile) &#123; long start = System.currentTimeMillis(); ZipOutputStream zos = null; File sourceFile = new File(srcDir); File zipFile = new File(zipPath); if(!sourceFile.exists())&#123; throw new RuntimeException(\"需压缩文件或者文件夹不存在\"); &#125; try &#123; zos = new ZipOutputStream(zipFile); compress(sourceFile, zos, sourceFile.getName()); if(isDelSrcFile)&#123; sourceFile.delete(); &#125; log.info(\"原文件:&#123;&#125;. 压缩到:&#123;&#125;完成. 是否删除原文件:&#123;&#125;. 耗时:&#123;&#125;ms. \",srcDir,zipPath,isDelSrcFile, System.currentTimeMillis()-start); &#125; catch (IOException e) &#123; log.error(\"zip error from AntZipUtil: &#123;&#125;. \",e.getMessage()); throw new RuntimeException(e); &#125; finally &#123; try &#123; if (zos != null) &#123;zos.finish();zos.close();&#125; &#125; catch (Exception e) &#123;&#125; &#125; &#125; /** * 递归压缩方法 * @param sourceFile 源文件 * @param zos zip输出流 * @param name 压缩后的名称 */ private static void compress(File sourceFile, ZipOutputStream zos, String name) throws IOException &#123; if (sourceFile.isFile()) &#123; byte[] buf = new byte[BUFFER_SIZE]; zos.putNextEntry(new ZipEntry(sourceFile,name)); int len; FileInputStream in = new FileInputStream(sourceFile); while ((len = in.read(buf)) != -1) &#123; zos.write(buf, 0, len); &#125; zos.closeEntry(); in.close(); &#125; else &#123; File[] listFiles = sourceFile.listFiles(); if (listFiles == null || listFiles.length == 0) &#123; zos.putNextEntry(new ZipEntry(sourceFile,name + \"/\")); zos.closeEntry(); &#125; else &#123; for (File file : listFiles) &#123; compress(file, zos, name + \"/\" + file.getName()); &#125; &#125; &#125; &#125; /** * 将多个文件压缩成zip，文件放在zip根目录，注意文件名相同会覆盖 * @param srcFiles 需要压缩的文件列表 * @param zipPath zip文件路径 * @throws RuntimeException 压缩失败会抛出运行时异常 */ public static void toZip(List&lt;File&gt; srcFiles , String zipPath) &#123; long start = System.currentTimeMillis(); File zipFile = new File(zipPath); File parentFile = zipFile.getParentFile(); if(!parentFile.exists()) parentFile.mkdirs(); FileOutputStream fos = null; ZipOutputStream zos = null; try &#123; fos = new FileOutputStream(zipPath); zos = new ZipOutputStream(new BufferedOutputStream(fos)); for (File srcFile : srcFiles) &#123; byte[] buf = new byte[BUFFER_SIZE]; zos.putNextEntry(new ZipEntry(srcFile.getName())); int len; FileInputStream in = new FileInputStream(srcFile); while ((len = in.read(buf)) != -1)&#123; zos.write(buf, 0, len); &#125; in.close(); zos.closeEntry(); &#125; long end = System.currentTimeMillis(); log.info(\"压缩完成，耗时：\" + (end - start) +\" ms\"); &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125;finally&#123; try &#123; if(zos != null)&#123; zos.finish(); zos.close(); &#125; if(fos != null) fos.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; /** * 把zip文件解压到指定的文件夹 * @param sourceFile zip文件, 如 \"D:/test/aa.zip\" * @param saveFileDir 解压后的文件存放路径, 如\"D:/test/\" () */ public static void unZip(File sourceFile, String saveFileDir) &#123; long start = System.currentTimeMillis(); // 判断源文件是否存在 if (!sourceFile.exists()) throw new RuntimeException(\"zip源文件不存在！\"); File dir = new File(saveFileDir); if(!dir.exists())&#123; dir.mkdirs(); &#125; File entryFile; ZipFile zipFile = null; InputStream inputStream = null; try &#123; zipFile = new ZipFile(sourceFile); for(Enumeration&lt;ZipEntry&gt; entries = zipFile.getEntries(); entries.hasMoreElements();)&#123; ZipEntry zipEntry = entries.nextElement(); entryFile = new File(saveFileDir + \"/\" + zipEntry.getName()); if(zipEntry.isDirectory())&#123; entryFile.mkdirs(); &#125; else &#123; File parent = entryFile.getParentFile(); if(parent!=null &amp;&amp; !parent.exists())&#123; parent.mkdirs(); &#125; OutputStream os = new BufferedOutputStream(new FileOutputStream( entryFile)); byte[] buffer = new byte[BUFFER_SIZE]; int len; inputStream = zipFile.getInputStream(zipEntry); while((len = inputStream.read(buffer)) != -1) &#123; os.write(buffer, 0, len); &#125; inputStream.close(); os.close(); &#125; &#125; long end = System.currentTimeMillis(); log.info(\"解压完成，耗时：&#123;&#125; ms\",end - start); &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125; finally &#123; try &#123; if(inputStream != null) inputStream.close(); if(zipFile != null) zipFile.close(); &#125; catch (IOException e) &#123; // nothing &#125; &#125; &#125;&#125;","tags":[{"name":"Zip,Java","slug":"Zip-Java","permalink":"http://yoursite.com/tags/Zip-Java/"}]}]